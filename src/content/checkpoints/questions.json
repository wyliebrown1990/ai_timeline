[
  {
    "id": "cp-chatgpt-1",
    "title": "Understanding Transformers",
    "pathId": "chatgpt-story",
    "afterMilestoneId": "E2017_TRANSFORMER",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-transformer-year",
        "question": "In what year was the Transformer architecture introduced?",
        "options": ["2015", "2016", "2017", "2018"],
        "correctIndex": 2,
        "explanation": "The Transformer was introduced in 2017 in the paper 'Attention Is All You Need' by Vaswani et al. at Google."
      },
      {
        "type": "multiple_choice",
        "id": "q-transformer-key",
        "question": "What is the key innovation of the Transformer architecture?",
        "options": [
          "Using more layers than previous models",
          "Processing sequences in parallel using attention",
          "Being smaller and faster than RNNs",
          "Using images instead of text"
        ],
        "correctIndex": 1,
        "explanation": "The Transformer's key innovation is using self-attention to process all parts of a sequence simultaneously, rather than one step at a time like RNNs."
      }
    ]
  },
  {
    "id": "cp-chatgpt-2",
    "title": "The GPT Evolution",
    "pathId": "chatgpt-story",
    "afterMilestoneId": "E2020_GPT3",
    "questions": [
      {
        "type": "ordering",
        "id": "q-gpt-timeline",
        "prompt": "Put these AI milestones in chronological order:",
        "items": [
          {"id": "gpt1", "label": "GPT-1", "date": "2018"},
          {"id": "transformer", "label": "Transformer", "date": "2017"},
          {"id": "gpt3", "label": "GPT-3", "date": "2020"},
          {"id": "gpt2", "label": "GPT-2", "date": "2019"}
        ],
        "correctOrder": ["transformer", "gpt1", "gpt2", "gpt3"]
      },
      {
        "type": "matching",
        "id": "q-gpt-params",
        "prompt": "Match each GPT version with its approximate parameter count:",
        "pairs": [
          {"id": "p1", "left": "GPT-1", "right": "117 million"},
          {"id": "p2", "left": "GPT-2", "right": "1.5 billion"},
          {"id": "p3", "left": "GPT-3", "right": "175 billion"}
        ]
      }
    ]
  },
  {
    "id": "cp-chatgpt-3",
    "title": "ChatGPT and RLHF",
    "pathId": "chatgpt-story",
    "afterMilestoneId": "E2022_CHATGPT",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-rlhf-purpose",
        "question": "What is the main purpose of RLHF (Reinforcement Learning from Human Feedback)?",
        "options": [
          "To make models faster",
          "To align model behavior with human preferences",
          "To reduce the number of parameters",
          "To enable image processing"
        ],
        "correctIndex": 1,
        "explanation": "RLHF trains models to produce outputs that humans rate as more helpful, honest, and harmless, aligning AI behavior with human values."
      },
      {
        "type": "multiple_choice",
        "id": "q-chatgpt-release",
        "question": "What made ChatGPT different from GPT-3 when it launched?",
        "options": [
          "It was much larger",
          "It was trained with RLHF to be conversational and safe",
          "It could process images",
          "It was open source"
        ],
        "correctIndex": 1,
        "explanation": "ChatGPT was built on GPT-3.5 but trained with RLHF (via InstructGPT techniques) to have natural conversations while refusing harmful requests."
      },
      {
        "type": "explain_back",
        "id": "q-explain-chatgpt",
        "concept": "ChatGPT's breakthrough significance",
        "prompt": "In your own words, explain why ChatGPT was such a breakthrough when it launched in November 2022.",
        "rubric": "A good explanation should mention: 1) ChatGPT combined a powerful language model with RLHF training for natural conversation, 2) It was freely accessible and user-friendly, making advanced AI available to everyone, 3) It could have back-and-forth conversations while refusing harmful requests. Credit for mentioning the rapid user adoption or comparison to previous AI assistants."
      }
    ]
  },
  {
    "id": "cp-fundamentals-1",
    "title": "Neural Network Foundations",
    "pathId": "ai-fundamentals",
    "afterMilestoneId": "E1958_PERCEPTRON",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-perceptron-concept",
        "question": "What was the perceptron designed to model?",
        "options": [
          "A single neuron in the brain",
          "The entire human brain",
          "A computer memory chip",
          "A calculator"
        ],
        "correctIndex": 0,
        "explanation": "The perceptron was an early attempt to model a single biological neuron, taking multiple inputs and producing a single output based on learned weights."
      },
      {
        "type": "multiple_choice",
        "id": "q-mcculloch-pitts",
        "question": "What did the McCulloch-Pitts paper (1943) establish?",
        "options": [
          "The first chatbot",
          "That neural computation is mathematically possible",
          "The internet protocol",
          "Deep learning algorithms"
        ],
        "correctIndex": 1,
        "explanation": "McCulloch and Pitts showed that networks of simple artificial neurons could, in principle, compute any logical function, establishing the theoretical foundation for neural networks."
      }
    ]
  },
  {
    "id": "cp-fundamentals-2",
    "title": "The Learning Breakthrough",
    "pathId": "ai-fundamentals",
    "afterMilestoneId": "E1986_BACKPROP",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-backprop-purpose",
        "question": "What problem does backpropagation solve?",
        "options": [
          "Making networks faster",
          "Teaching networks with multiple layers to learn",
          "Compressing data",
          "Connecting to the internet"
        ],
        "correctIndex": 1,
        "explanation": "Backpropagation allows error signals to flow backward through multiple layers, telling each connection how to adjust to improve the network's performance."
      },
      {
        "type": "ordering",
        "id": "q-early-ai-timeline",
        "prompt": "Put these early AI milestones in order:",
        "items": [
          {"id": "perceptron", "label": "Perceptron", "date": "1958"},
          {"id": "mcculloch", "label": "McCulloch-Pitts Paper", "date": "1943"},
          {"id": "backprop", "label": "Backpropagation", "date": "1986"},
          {"id": "eliza", "label": "ELIZA chatbot", "date": "1966"}
        ],
        "correctOrder": ["mcculloch", "perceptron", "eliza", "backprop"]
      }
    ]
  },
  {
    "id": "cp-fundamentals-3",
    "title": "Deep Learning Revolution",
    "pathId": "ai-fundamentals",
    "afterMilestoneId": "E2012_ALEXNET",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-alexnet-impact",
        "question": "Why was AlexNet (2012) considered revolutionary?",
        "options": [
          "It was the first neural network ever",
          "It dramatically outperformed traditional methods on image recognition",
          "It could generate text",
          "It was open source"
        ],
        "correctIndex": 1,
        "explanation": "AlexNet reduced ImageNet error rates by nearly half compared to traditional methods, proving that deep learning could solve real problems and sparking the deep learning revolution."
      },
      {
        "type": "multiple_choice",
        "id": "q-deep-learning-why",
        "question": "What combination made deep learning practical by 2012?",
        "options": [
          "Better scientists and bigger labs",
          "Big data, GPUs, and better algorithms",
          "Government funding and quantum computers",
          "Faster internet connections"
        ],
        "correctIndex": 1,
        "explanation": "The deep learning revolution was enabled by the availability of large datasets (like ImageNet), powerful GPU computing, and algorithmic improvements like better initialization and activation functions."
      },
      {
        "type": "explain_back",
        "id": "q-explain-deep-learning",
        "concept": "Deep learning vs. earlier neural networks",
        "prompt": "Explain in simple terms what makes 'deep' learning different from earlier neural networks.",
        "rubric": "A good explanation should cover: 1) Deep learning uses many layers (hence 'deep'), unlike earlier 1-2 layer networks, 2) Deep networks learn hierarchical features - from simple (edges) to complex (objects), 3) This enables solving harder problems like image recognition or language understanding. Bonus for mentioning the computational requirements or specific breakthroughs."
      }
    ]
  },
  {
    "id": "cp-fundamentals-4",
    "title": "Generative AI",
    "pathId": "ai-fundamentals",
    "afterMilestoneId": "E2014_GANS",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-gan-concept",
        "question": "How do GANs (Generative Adversarial Networks) learn to generate realistic images?",
        "options": [
          "By copying existing images exactly",
          "Through competition between a generator and discriminator",
          "By following human-written rules",
          "By connecting to image databases"
        ],
        "correctIndex": 1,
        "explanation": "GANs use two networks that compete: one generates fake images while the other tries to detect fakes. This adversarial training pushes the generator to produce increasingly realistic outputs."
      },
      {
        "type": "matching",
        "id": "q-nn-architectures",
        "prompt": "Match each architecture to what it's best at:",
        "pairs": [
          {"id": "p1", "left": "CNN", "right": "Image recognition"},
          {"id": "p2", "left": "GAN", "right": "Image generation"},
          {"id": "p3", "left": "Transformer", "right": "Language understanding"}
        ]
      }
    ]
  },
  {
    "id": "cp-governance-1",
    "title": "AI Ethics and Safety",
    "pathId": "ai-governance",
    "afterMilestoneId": "E2022_CONSTITUTIONAL_AI",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-constitutional-ai",
        "question": "What is Constitutional AI's approach to making AI safer?",
        "options": [
          "Limiting AI to simple tasks only",
          "Using a set of principles for AI to self-critique and improve",
          "Having humans review every AI output",
          "Making AI models smaller"
        ],
        "correctIndex": 1,
        "explanation": "Constitutional AI gives the model a set of principles (a 'constitution') and trains it to critique and revise its own outputs according to those principles, making safety more scalable."
      },
      {
        "type": "multiple_choice",
        "id": "q-rlhf-vs-cai",
        "question": "How does Constitutional AI differ from standard RLHF?",
        "options": [
          "It doesn't use any human feedback",
          "It uses explicit principles for AI self-improvement, reducing human labeling needs",
          "It makes models larger",
          "It only works for images"
        ],
        "correctIndex": 1,
        "explanation": "While RLHF relies heavily on human raters, Constitutional AI uses explicit principles that the AI applies to critique its own outputs, making the alignment process more transparent and scalable."
      }
    ]
  },
  {
    "id": "cp-governance-2",
    "title": "AI Regulation Landscape",
    "pathId": "ai-governance",
    "afterMilestoneId": "E2024_EU_AI_ACT",
    "questions": [
      {
        "type": "ordering",
        "id": "q-regulation-timeline",
        "prompt": "Put these AI governance milestones in chronological order:",
        "items": [
          {"id": "openai-charter", "label": "OpenAI Charter", "date": "2018"},
          {"id": "oecd", "label": "OECD AI Principles", "date": "2019"},
          {"id": "nist", "label": "NIST AI Risk Management Framework", "date": "2023"},
          {"id": "eu-act", "label": "EU AI Act", "date": "2024"}
        ],
        "correctOrder": ["openai-charter", "oecd", "nist", "eu-act"]
      },
      {
        "type": "multiple_choice",
        "id": "q-eu-ai-act",
        "question": "What approach does the EU AI Act take to regulating AI?",
        "options": [
          "Banning all AI development",
          "Risk-based regulation with different rules for different risk levels",
          "Requiring all AI to be open source",
          "Only regulating government AI use"
        ],
        "correctIndex": 1,
        "explanation": "The EU AI Act uses a risk-based approach: minimal-risk AI has few restrictions, while high-risk AI (like hiring tools) must meet strict requirements, and some uses are banned entirely."
      },
      {
        "type": "explain_back",
        "id": "q-explain-governance",
        "concept": "AI governance importance for business",
        "prompt": "Why is AI governance important for businesses deploying AI systems?",
        "rubric": "A good explanation should include: 1) Legal compliance - regulations like EU AI Act have penalties, 2) Risk management - safety failures cause reputational and legal issues, 3) Customer trust - well-governed AI is more reliable, 4) Proactive risk identification before deployment. Credit for mentioning specific regulations or real-world examples of governance failures."
      }
    ]
  },
  {
    "id": "cp-image-gen-1",
    "title": "AI Image Generation Basics",
    "pathId": "ai-image-generation",
    "afterMilestoneId": "E2021_DALLE",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-dalle-innovation",
        "question": "What made DALL-E (2021) significant in AI history?",
        "options": [
          "It was the first image recognition system",
          "It could generate images from text descriptions",
          "It could only process existing photos",
          "It was faster than GANs"
        ],
        "correctIndex": 1,
        "explanation": "DALL-E was revolutionary because it could generate novel images from text prompts, combining language understanding (from transformers) with image generation capabilities."
      },
      {
        "type": "multiple_choice",
        "id": "q-clip-role",
        "question": "What role does CLIP play in image generation systems?",
        "options": [
          "It generates the images directly",
          "It connects text understanding to visual concepts",
          "It compresses image files",
          "It stores images in databases"
        ],
        "correctIndex": 1,
        "explanation": "CLIP learns to match images with text descriptions, enabling systems to understand what 'a sunset over mountains' should look like and guide image generation accordingly."
      }
    ]
  },
  {
    "id": "cp-image-gen-2",
    "title": "Diffusion Models",
    "pathId": "ai-image-generation",
    "afterMilestoneId": "E2022_STABLE_DIFFUSION_RELEASE",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-diffusion-process",
        "question": "How do diffusion models generate images?",
        "options": [
          "By copying parts of existing images",
          "By starting with noise and gradually removing it",
          "By drawing shapes one at a time",
          "By converting text directly to pixels"
        ],
        "correctIndex": 1,
        "explanation": "Diffusion models start with random noise and learn to gradually 'denoise' it into a coherent image, guided by the text prompt. Each step removes some noise until a clear image emerges."
      },
      {
        "type": "matching",
        "id": "q-image-gen-tools",
        "prompt": "Match each tool to its underlying technology:",
        "pairs": [
          {"id": "p1", "left": "Stable Diffusion", "right": "Latent diffusion model"},
          {"id": "p2", "left": "Early StyleGAN", "right": "GAN architecture"},
          {"id": "p3", "left": "DALL-E 2", "right": "Diffusion + CLIP"}
        ]
      },
      {
        "type": "explain_back",
        "id": "q-explain-diffusion-vs-gan",
        "concept": "Diffusion models vs GANs",
        "prompt": "Explain one advantage of diffusion models over GANs for image generation.",
        "rubric": "A good explanation should mention at least one valid advantage: 1) Training stability - diffusion models don't suffer from mode collapse like GANs, 2) Image quality - diffusion often produces higher quality results, 3) Controllability - easier to guide generation with text prompts, 4) Diversity - better at producing varied outputs. Accept any well-explained advantage."
      }
    ]
  },
  {
    "id": "cp-business-1",
    "title": "Early AI in Business",
    "pathId": "ai-for-business",
    "afterMilestoneId": "E1997_DEEP_BLUE",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-expert-systems-use",
        "question": "What was the primary business application of expert systems in the 1980s?",
        "options": [
          "Social media marketing",
          "Encoding specialist knowledge for decision support",
          "Generating creative content",
          "Autonomous vehicle control"
        ],
        "correctIndex": 1,
        "explanation": "Expert systems captured the decision-making knowledge of human specialists, enabling businesses to automate complex decisions in areas like medical diagnosis, loan approval, and equipment maintenance."
      },
      {
        "type": "multiple_choice",
        "id": "q-deep-blue-lesson",
        "question": "What business lesson did Deep Blue's 1997 victory over Kasparov demonstrate?",
        "options": [
          "AI will replace all human workers",
          "Specialized AI can outperform humans in narrow domains",
          "AI is better at everything",
          "Chess players are no longer needed"
        ],
        "correctIndex": 1,
        "explanation": "Deep Blue showed that AI could exceed human capabilities in specific, well-defined tasks. This principle guides AI adoption today: focus AI on narrow domains where it excels, while humans handle broader judgment."
      }
    ]
  },
  {
    "id": "cp-business-2",
    "title": "The Deep Learning Business Impact",
    "pathId": "ai-for-business",
    "afterMilestoneId": "E2020_GPT3",
    "questions": [
      {
        "type": "ordering",
        "id": "q-ai-business-timeline",
        "prompt": "Put these AI business milestones in chronological order:",
        "items": [
          {"id": "expert", "label": "Expert systems in enterprises", "date": "1980s"},
          {"id": "deep-blue", "label": "Deep Blue beats Kasparov", "date": "1997"},
          {"id": "alexnet", "label": "AlexNet enables practical computer vision", "date": "2012"},
          {"id": "gpt3", "label": "GPT-3 enables text generation at scale", "date": "2020"}
        ],
        "correctOrder": ["expert", "deep-blue", "alexnet", "gpt3"]
      },
      {
        "type": "multiple_choice",
        "id": "q-gpt3-business",
        "question": "What new business capability did GPT-3 enable compared to earlier AI?",
        "options": [
          "Image recognition in factories",
          "General-purpose text generation and understanding",
          "Faster database queries",
          "Robotic automation"
        ],
        "correctIndex": 1,
        "explanation": "GPT-3's ability to generate coherent text and follow instructions opened new use cases: customer service automation, content generation, code assistance, and more—tasks that required human language skills."
      },
      {
        "type": "matching",
        "id": "q-ai-business-apps",
        "prompt": "Match each AI milestone to its primary business application:",
        "pairs": [
          {"id": "p1", "left": "Expert Systems", "right": "Decision support & diagnostics"},
          {"id": "p2", "left": "AlexNet/Computer Vision", "right": "Quality inspection & image analysis"},
          {"id": "p3", "left": "GPT-3/LLMs", "right": "Content generation & automation"}
        ]
      }
    ]
  },
  {
    "id": "cp-business-3",
    "title": "Modern AI Strategy",
    "pathId": "ai-for-business",
    "afterMilestoneId": "E2023_GPT4",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-chatgpt-disruption",
        "question": "Why did ChatGPT's launch in 2022 change business AI adoption?",
        "options": [
          "It was the first AI ever created",
          "It made advanced AI accessible through a simple chat interface",
          "It replaced all existing software",
          "It only worked for large corporations"
        ],
        "correctIndex": 1,
        "explanation": "ChatGPT democratized AI by providing a simple, conversational interface. Suddenly anyone could use advanced AI without technical expertise, forcing businesses to quickly develop AI strategies."
      },
      {
        "type": "multiple_choice",
        "id": "q-gpt4-multimodal",
        "question": "What capability did GPT-4 add that expanded business use cases?",
        "options": [
          "Faster text generation only",
          "Multimodal abilities (processing images and text together)",
          "Hardware manufacturing",
          "Physical robot control"
        ],
        "correctIndex": 1,
        "explanation": "GPT-4's multimodal capabilities enabled new applications: analyzing charts and documents, processing receipts, understanding diagrams, and more—expanding AI's usefulness across industries."
      },
      {
        "type": "explain_back",
        "id": "q-explain-ai-strategy",
        "concept": "AI adoption strategy for businesses",
        "prompt": "Based on the evolution from expert systems to GPT-4, what should a business leader consider when adopting AI today?",
        "rubric": "A good response should include: 1) Start with specific, well-defined use cases (lesson from expert systems and Deep Blue), 2) Consider data requirements and availability, 3) Balance automation with human oversight, 4) Stay current as capabilities rapidly evolve (from GPT-3 to GPT-4 in just a few years). Bonus for mentioning risks, costs, or change management."
      }
    ]
  },
  {
    "id": "cp-everyday-1",
    "title": "Quick Check: AI Writing",
    "pathId": "ai-for-everyday-life",
    "afterMilestoneId": "E2020_GPT3",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-everyday-ai-write",
        "question": "What can AI writing tools like GPT-3 do?",
        "options": [
          "Actually understand what they're writing",
          "Predict what words should come next based on patterns",
          "Think and reason like a human",
          "Always give correct information"
        ],
        "correctIndex": 1,
        "explanation": "AI writing tools work by predicting what words should come next, based on patterns from millions of documents. They don't actually understand or think—they're very good at pattern matching."
      },
      {
        "type": "multiple_choice",
        "id": "q-everyday-trust",
        "question": "When should you trust information from AI?",
        "options": [
          "Always—AI is very accurate",
          "Never—AI is always wrong",
          "With caution—verify important information from other sources",
          "Only for medical and legal advice"
        ],
        "correctIndex": 2,
        "explanation": "The best approach is healthy skepticism. AI can be helpful but also confidently wrong. Always verify important information, especially for health, legal, or financial decisions."
      }
    ]
  },
  {
    "id": "cp-everyday-2",
    "title": "Quick Check: AI Images",
    "pathId": "ai-for-everyday-life",
    "afterMilestoneId": "E2021_DALLE",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-everyday-ai-image",
        "question": "How can you often spot an AI-generated image?",
        "options": [
          "AI images are always blurry",
          "Look for strange hands, scrambled text, or odd backgrounds",
          "AI images are always black and white",
          "There's no way to tell"
        ],
        "correctIndex": 1,
        "explanation": "Common signs of AI images include: hands with too many or too few fingers, text that looks scrambled, backgrounds that don't quite make sense, and faces that seem 'too perfect.'"
      },
      {
        "type": "multiple_choice",
        "id": "q-everyday-photo-trust",
        "question": "A friend shares an amazing photo on social media. What should you consider?",
        "options": [
          "All photos online are real",
          "It could be AI-generated, especially if it seems too perfect or outrageous",
          "Only professional photographers use AI",
          "AI can only make cartoon images"
        ],
        "correctIndex": 1,
        "explanation": "AI can now create very realistic photos. If something seems too perfect, too outrageous, or too good to be true, it's worth questioning whether it's real."
      }
    ]
  },
  {
    "id": "cp-everyday-3",
    "title": "Quick Check: ChatGPT",
    "pathId": "ai-for-everyday-life",
    "afterMilestoneId": "E2022_CHATGPT",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-everyday-chatgpt-good",
        "question": "What is ChatGPT good for?",
        "options": [
          "Getting accurate medical diagnosis",
          "Making important financial decisions",
          "Helping draft letters, explain concepts, or brainstorm ideas",
          "Providing legal advice"
        ],
        "correctIndex": 2,
        "explanation": "ChatGPT is helpful for everyday tasks like writing drafts, getting explanations, or brainstorming. But it should never be used for medical, legal, or financial advice—always consult professionals for those."
      },
      {
        "type": "multiple_choice",
        "id": "q-everyday-scam-warning",
        "question": "Your 'grandchild' calls asking for emergency money. The voice sounds like them. What should you do?",
        "options": [
          "Send money immediately—family comes first",
          "Hang up and call them back at their real phone number",
          "Ask for their bank account details",
          "AI can't clone voices, so it must be real"
        ],
        "correctIndex": 1,
        "explanation": "AI can now clone voices very convincingly. If anyone calls asking for money—even if they sound like family—hang up and call them back at a number you know is real. This is a common scam."
      }
    ]
  },
  {
    "id": "cp-everyday-4",
    "title": "Final Check: AI Today",
    "pathId": "ai-for-everyday-life",
    "afterMilestoneId": "E2023_GPT4",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-everyday-ai-limits",
        "question": "What should you remember about AI tools like ChatGPT and GPT-4?",
        "options": [
          "They're always correct because they're computers",
          "They can be confidently wrong, so always verify important information",
          "They have no practical uses",
          "They're too complicated for regular people to use"
        ],
        "correctIndex": 1,
        "explanation": "AI tools can be very helpful, but they can also be confidently wrong. Always verify important information from trusted sources, especially for health, money, or legal matters."
      },
      {
        "type": "multiple_choice",
        "id": "q-everyday-safe-use",
        "question": "What's a safe way to try AI tools like ChatGPT?",
        "options": [
          "Share your social security number to verify your identity",
          "Give it your passwords so it can help with your accounts",
          "Ask it to explain something you're curious about, like a recipe or hobby",
          "Tell it your bank account information"
        ],
        "correctIndex": 2,
        "explanation": "Never share personal information like passwords, social security numbers, or financial details with AI tools. Safe uses include asking questions, getting explanations, or help with writing—nothing that requires sensitive information."
      }
    ]
  }
]
