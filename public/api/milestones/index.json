{
  "data": [
    {
      "id": "E1943_MCCULLOCH_PITTS",
      "title": "McCulloch and Pitts formalize a mathematical model of neurons",
      "description": "Early computational neuroscience work that helped inspire neural network thinking.",
      "date": "1943-01-01",
      "category": "research",
      "significance": 1,
      "era": "Foundations",
      "organization": null,
      "contributors": [
        "Warren McCulloch",
        "Walter Pitts"
      ],
      "sourceUrl": "https://homes.cs.washington.edu/~pedrod/papers/mcculloch43.pdf",
      "imageUrl": null,
      "tags": [
        "Artificial neuron",
        "Neural networks"
      ],
      "sources": [
        {
          "label": "Paper (PDF)",
          "kind": "paper",
          "url": "https://homes.cs.washington.edu/~pedrod/papers/mcculloch43.pdf"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E1948_SHANNON_INFORMATION_THEORY",
      "title": "Shannon publishes 'A Mathematical Theory of Communication'",
      "description": "Defines information theory, foundational for modern communication and learning systems.",
      "date": "1948-01-01",
      "category": "research",
      "significance": 3,
      "era": "Foundations",
      "organization": null,
      "contributors": [
        "Claude Shannon"
      ],
      "sourceUrl": "https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf",
      "imageUrl": null,
      "tags": [
        "Entropy",
        "Information theory"
      ],
      "sources": [
        {
          "label": "Paper (PDF)",
          "kind": "paper",
          "url": "https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E1950_TURING_TEST",
      "title": "Alan Turing proposes the 'Imitation Game' (Turing Test)",
      "description": "Frames machine intelligence via conversational indistinguishability.",
      "date": "1950-01-01",
      "category": "research",
      "significance": 1,
      "era": "Foundations",
      "organization": null,
      "contributors": [
        "Alan Turing"
      ],
      "sourceUrl": "https://academic.oup.com/mind/article/LIX/236/433/986238",
      "imageUrl": null,
      "tags": [
        "Turing Test",
        "Machine intelligence"
      ],
      "sources": [
        {
          "label": "Journal article (Mind)",
          "kind": "paper",
          "url": "https://academic.oup.com/mind/article/LIX/236/433/986238"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E1955_DARTMOUTH_PROPOSAL",
      "title": "Dartmouth Summer Research Project proposal coins 'Artificial Intelligence'",
      "description": "The proposal that popularized the term and agenda of AI research.",
      "date": "1955-01-01",
      "category": "research",
      "significance": 2,
      "era": "Foundations",
      "organization": null,
      "contributors": [
        "John McCarthy",
        "Marvin Minsky",
        "Nathaniel Rochester",
        "Claude Shannon"
      ],
      "sourceUrl": "http://jmc.stanford.edu/articles/dartmouth/dartmouth.pdf",
      "imageUrl": null,
      "tags": [
        "Artificial Intelligence"
      ],
      "sources": [
        {
          "label": "Proposal (PDF)",
          "kind": "primary_doc",
          "url": "http://jmc.stanford.edu/articles/dartmouth/dartmouth.pdf"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E1958_PERCEPTRON",
      "title": "Rosenblatt introduces the Perceptron",
      "description": "A trainable linear classifier that shaped early neural network optimism.",
      "date": "1958-01-01",
      "category": "research",
      "significance": 1,
      "era": "Early Neural Nets",
      "organization": null,
      "contributors": [
        "Frank Rosenblatt"
      ],
      "sourceUrl": "https://doi.org/10.1037/h0042519",
      "imageUrl": null,
      "tags": [
        "Perceptron",
        "Linear classifier"
      ],
      "sources": [
        {
          "label": "Paper (Psychological Review)",
          "kind": "paper",
          "url": "https://doi.org/10.1037/h0042519"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E1966_ELIZA",
      "title": "Weizenbaum publishes ELIZA",
      "description": "A landmark conversational program demonstrating pattern-based dialogue.",
      "date": "1966-01-01",
      "category": "research",
      "significance": 1,
      "era": "Symbolic AI and Early NLP",
      "organization": null,
      "contributors": [
        "Joseph Weizenbaum"
      ],
      "sourceUrl": "https://dl.acm.org/doi/10.1145/365153.365168",
      "imageUrl": null,
      "tags": [
        "Chatbots",
        "NLP"
      ],
      "sources": [
        {
          "label": "Paper (CACM)",
          "kind": "paper",
          "url": "https://dl.acm.org/doi/10.1145/365153.365168"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E1969_PERCEPTRONS_BOOK",
      "title": "Minsky and Papert publish 'Perceptrons'",
      "description": "Highlights limitations of single-layer perceptrons and shapes an AI winter narrative.",
      "date": "1969-01-01",
      "category": "research",
      "significance": 1,
      "era": "Early Neural Nets",
      "organization": null,
      "contributors": [
        "Marvin Minsky",
        "Seymour Papert"
      ],
      "sourceUrl": "https://mitpress.mit.edu/9780262630221/perceptrons/",
      "imageUrl": null,
      "tags": [
        "Perceptrons",
        "Model limitations"
      ],
      "sources": [
        {
          "label": "Book (MIT Press)",
          "kind": "book",
          "url": "https://mitpress.mit.edu/9780262630221/perceptrons/"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E1972_PROLOG",
      "title": "Prolog emerges as a logic programming language",
      "description": "Logic programming becomes a major paradigm for symbolic AI.",
      "date": "1972-01-01",
      "category": "research",
      "significance": 1,
      "era": "Symbolic AI",
      "organization": null,
      "contributors": [
        "Alain Colmerauer",
        "Philippe Roussel"
      ],
      "sourceUrl": "https://www-sop.inria.fr/manifestations/Prolog50/Prolog50-history.html",
      "imageUrl": null,
      "tags": [
        "Logic programming",
        "Prolog"
      ],
      "sources": [
        {
          "label": "Historical note (INRIA)",
          "kind": "primary_doc",
          "url": "https://www-sop.inria.fr/manifestations/Prolog50/Prolog50-history.html"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E1980_EXPERT_SYSTEMS_RISE",
      "title": "Expert systems become commercially influential",
      "description": "Rule-based systems see widespread enterprise adoption before later limitations surface.",
      "date": "1980-01-01",
      "category": "industry",
      "significance": 1,
      "era": "Expert Systems",
      "organization": null,
      "contributors": [],
      "sourceUrl": "https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/411",
      "imageUrl": null,
      "tags": [
        "Expert systems",
        "Knowledge engineering"
      ],
      "sources": [
        {
          "label": "Classic overview (AI Magazine)",
          "kind": "paper",
          "url": "https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/411"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E1986_BACKPROP",
      "title": "Backpropagation popularized for learning representations",
      "description": "Backprop becomes the practical workhorse for training multi-layer neural networks.",
      "date": "1986-01-01",
      "category": "research",
      "significance": 3,
      "era": "Neural Nets Revival",
      "organization": null,
      "contributors": [
        "David Rumelhart",
        "Geoffrey Hinton",
        "Ronald Williams"
      ],
      "sourceUrl": "https://www.nature.com/articles/323533a0",
      "imageUrl": null,
      "tags": [
        "Backpropagation",
        "Gradient descent"
      ],
      "sources": [
        {
          "label": "Paper (Nature)",
          "kind": "paper",
          "url": "https://www.nature.com/articles/323533a0"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E1995_SVM",
      "title": "Support Vector Machines formalized",
      "description": "SVMs become a dominant approach in supervised learning for years.",
      "date": "1995-01-01",
      "category": "research",
      "significance": 1,
      "era": "Statistical ML",
      "organization": null,
      "contributors": [
        "Corinna Cortes",
        "Vladimir Vapnik"
      ],
      "sourceUrl": "https://link.springer.com/article/10.1007/BF00994018",
      "imageUrl": null,
      "tags": [
        "SVM",
        "Margin maximization"
      ],
      "sources": [
        {
          "label": "Paper (Machine Learning)",
          "kind": "paper",
          "url": "https://link.springer.com/article/10.1007/BF00994018"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E1997_LSTM",
      "title": "Long Short-Term Memory (LSTM) introduced",
      "description": "Addresses vanishing gradients and enables long-range sequence learning.",
      "date": "1997-01-01",
      "category": "research",
      "significance": 2,
      "era": "Neural Nets",
      "organization": null,
      "contributors": [
        "Sepp Hochreiter",
        "Jürgen Schmidhuber"
      ],
      "sourceUrl": "https://doi.org/10.1162/neco.1997.9.8.1735",
      "imageUrl": null,
      "tags": [
        "LSTM",
        "Recurrent neural networks"
      ],
      "sources": [
        {
          "label": "Paper (Neural Computation)",
          "kind": "paper",
          "url": "https://doi.org/10.1162/neco.1997.9.8.1735"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E1997_DEEP_BLUE",
      "title": "IBM Deep Blue defeats Garry Kasparov",
      "description": "A symbolic and brute-force search milestone for human-competitive performance.",
      "date": "1997-01-01",
      "category": "breakthrough",
      "significance": 3,
      "era": "Milestones",
      "organization": null,
      "contributors": [
        "Garry Kasparov"
      ],
      "sourceUrl": "https://www.ibm.com/ibm/history/ibm100/us/en/icons/deepblue/",
      "imageUrl": null,
      "tags": [
        "Game-playing AI",
        "Search"
      ],
      "sources": [
        {
          "label": "IBM archive (primary)",
          "kind": "primary_doc",
          "url": "https://www.ibm.com/ibm/history/ibm100/us/en/icons/deepblue/"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E1998_LENET",
      "title": "LeCun et al. publish gradient-based learning for document recognition (LeNet era)",
      "description": "CNNs applied effectively to real-world vision tasks like handwriting recognition.",
      "date": "1998-01-01",
      "category": "research",
      "significance": 1,
      "era": "Deep Learning Precursors",
      "organization": null,
      "contributors": [
        "Yann LeCun",
        "Léon Bottou",
        "Yoshua Bengio",
        "Patrick Haffner"
      ],
      "sourceUrl": "http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf",
      "imageUrl": null,
      "tags": [
        "CNN",
        "Computer vision"
      ],
      "sources": [
        {
          "label": "Paper (PDF)",
          "kind": "paper",
          "url": "http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2006_DEEP_BELIEF_NETS",
      "title": "Hinton et al. publish Deep Belief Nets training method",
      "description": "Helps restart interest in deep architectures via layer-wise pretraining.",
      "date": "2006-01-01",
      "category": "research",
      "significance": 1,
      "era": "Deep Learning Emerges",
      "organization": null,
      "contributors": [
        "Geoffrey Hinton",
        "Simon Osindero",
        "Yee-Whye Teh"
      ],
      "sourceUrl": "https://doi.org/10.1162/neco.2006.18.7.1527",
      "imageUrl": null,
      "tags": [
        "Deep learning",
        "Representation learning"
      ],
      "sources": [
        {
          "label": "Paper (Neural Computation)",
          "kind": "paper",
          "url": "https://doi.org/10.1162/neco.2006.18.7.1527"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2009_IMAGENET",
      "title": "ImageNet dataset introduced",
      "description": "Large-scale labeled data becomes a catalyst for modern computer vision.",
      "date": "2009-01-01",
      "category": "research",
      "significance": 1,
      "era": "Deep Learning Emerges",
      "organization": null,
      "contributors": [
        "Jia Deng",
        "Fei-Fei Li"
      ],
      "sourceUrl": "https://www.image-net.org/static_files/papers/imagenet_cvpr09.pdf",
      "imageUrl": null,
      "tags": [
        "Datasets",
        "Supervised learning"
      ],
      "sources": [
        {
          "label": "Paper (CVPR) PDF",
          "kind": "paper",
          "url": "https://www.image-net.org/static_files/papers/imagenet_cvpr09.pdf"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2012_ALEXNET",
      "title": "AlexNet wins ImageNet and popularizes GPU deep learning",
      "description": "A decisive ImageNet breakthrough that accelerates deep learning adoption.",
      "date": "2012-01-01",
      "category": "research",
      "significance": 3,
      "era": "Deep Learning Boom",
      "organization": null,
      "contributors": [
        "Alex Krizhevsky",
        "Ilya Sutskever",
        "Geoffrey Hinton"
      ],
      "sourceUrl": "https://proceedings.neurips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf",
      "imageUrl": null,
      "tags": [
        "CNN",
        "GPU training"
      ],
      "sources": [
        {
          "label": "NeurIPS paper (PDF)",
          "kind": "paper",
          "url": "https://proceedings.neurips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2013_WORD2VEC",
      "title": "word2vec introduces efficient neural word embeddings",
      "description": "Embeddings become a standard representation for language modeling pipelines.",
      "date": "2013-01-01",
      "category": "research",
      "significance": 2,
      "era": "Deep Learning Boom",
      "organization": null,
      "contributors": [
        "Tomas Mikolov"
      ],
      "sourceUrl": "https://arxiv.org/abs/1301.3781",
      "imageUrl": null,
      "tags": [
        "Embeddings",
        "Distributional semantics"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/1301.3781"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2014_SEQ2SEQ",
      "title": "Sequence-to-sequence learning with neural networks",
      "description": "Encoder-decoder framing for translation and other sequence tasks.",
      "date": "2014-01-01",
      "category": "research",
      "significance": 1,
      "era": "Seq2Seq and Attention",
      "organization": null,
      "contributors": [
        "Ilya Sutskever",
        "Oriol Vinyals",
        "Quoc V. Le"
      ],
      "sourceUrl": "https://arxiv.org/abs/1409.3215",
      "imageUrl": null,
      "tags": [
        "Seq2Seq",
        "Encoder-decoder"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/1409.3215"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2014_ATTENTION_NMT",
      "title": "Neural machine translation with attention alignment",
      "description": "Demonstrates learned alignment. A key step toward Transformers.",
      "date": "2014-01-01",
      "category": "research",
      "significance": 2,
      "era": "Seq2Seq and Attention",
      "organization": null,
      "contributors": [
        "Dzmitry Bahdanau",
        "Kyunghyun Cho",
        "Yoshua Bengio"
      ],
      "sourceUrl": "https://arxiv.org/abs/1409.0473",
      "imageUrl": null,
      "tags": [
        "Attention",
        "Neural machine translation"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/1409.0473"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2014_ADAM",
      "title": "Adam optimizer introduced",
      "description": "Becomes a widely used adaptive optimizer for training neural nets.",
      "date": "2014-01-01",
      "category": "research",
      "significance": 2,
      "era": "Deep Learning Boom",
      "organization": null,
      "contributors": [
        "Diederik Kingma",
        "Jimmy Ba"
      ],
      "sourceUrl": "https://arxiv.org/abs/1412.6980",
      "imageUrl": null,
      "tags": [
        "Optimization",
        "Adam"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/1412.6980"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2014_GANS",
      "title": "Generative Adversarial Networks (GANs) introduced",
      "description": "Adversarial training becomes a major paradigm for generative modeling.",
      "date": "2014-01-01",
      "category": "model_release",
      "significance": 2,
      "era": "Generative Models",
      "organization": null,
      "contributors": [
        "Ian Goodfellow"
      ],
      "sourceUrl": "https://arxiv.org/abs/1406.2661",
      "imageUrl": null,
      "tags": [
        "GANs",
        "Generative modeling"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/1406.2661"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2014_DROPOUT",
      "title": "Dropout popularized as regularization",
      "description": "Improves generalization and becomes a default deep learning technique.",
      "date": "2014-01-01",
      "category": "research",
      "significance": 1,
      "era": "Deep Learning Boom",
      "organization": null,
      "contributors": [
        "Nitish Srivastava",
        "Geoffrey Hinton"
      ],
      "sourceUrl": "https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf",
      "imageUrl": null,
      "tags": [
        "Regularization",
        "Dropout"
      ],
      "sources": [
        {
          "label": "Paper (JMLR) PDF",
          "kind": "paper",
          "url": "https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2015_BATCHNORM",
      "title": "Batch Normalization introduced",
      "description": "Stabilizes and accelerates training for deep networks.",
      "date": "2015-01-01",
      "category": "research",
      "significance": 1,
      "era": "Deep Learning Boom",
      "organization": null,
      "contributors": [
        "Sergey Ioffe",
        "Christian Szegedy"
      ],
      "sourceUrl": "https://arxiv.org/abs/1502.03167",
      "imageUrl": null,
      "tags": [
        "Normalization",
        "Training stability"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/1502.03167"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2015_RESNET",
      "title": "ResNet enables very deep networks via residual connections",
      "description": "Residual learning becomes a backbone of modern vision architectures.",
      "date": "2015-01-01",
      "category": "research",
      "significance": 2,
      "era": "Deep Learning Boom",
      "organization": null,
      "contributors": [
        "Kaiming He",
        "Xiangyu Zhang",
        "Shaoqing Ren",
        "Jian Sun"
      ],
      "sourceUrl": "https://arxiv.org/abs/1512.03385",
      "imageUrl": null,
      "tags": [
        "Residual connections",
        "CNN"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/1512.03385"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2016_ALPHAGO",
      "title": "DeepMind publishes AlphaGo results",
      "description": "Deep RL plus search achieves pro-level Go and shocks the field.",
      "date": "2016-01-01",
      "category": "breakthrough",
      "significance": 3,
      "era": "Reinforcement Learning Milestones",
      "organization": null,
      "contributors": [
        "David Silver",
        "Demis Hassabis"
      ],
      "sourceUrl": "https://augmentingcognition.com/assets/Silver2016a.pdf",
      "imageUrl": null,
      "tags": [
        "Deep reinforcement learning",
        "Monte Carlo tree search"
      ],
      "sources": [
        {
          "label": "Nature paper (PDF mirror)",
          "kind": "paper",
          "url": "https://augmentingcognition.com/assets/Silver2016a.pdf"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2017_PPO",
      "title": "Proximal Policy Optimization (PPO) introduced",
      "description": "PPO becomes a standard RL algorithm. Later widely used in RLHF pipelines.",
      "date": "2017-01-01",
      "category": "research",
      "significance": 2,
      "era": "Reinforcement Learning",
      "organization": null,
      "contributors": [
        "John Schulman"
      ],
      "sourceUrl": "https://arxiv.org/abs/1707.06347",
      "imageUrl": null,
      "tags": [
        "PPO",
        "Policy gradients"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/1707.06347"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2017_TRANSFORMER",
      "title": "Transformer architecture introduced",
      "description": "Replaces recurrence with self-attention. A key foundation for modern LLMs.",
      "date": "2017-06-12",
      "category": "model_release",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Ashish Vaswani",
        "Noam Shazeer",
        "Niki Parmar",
        "Jakob Uszkoreit",
        "Llion Jones",
        "Aidan Gomez",
        "Łukasz Kaiser",
        "Illia Polosukhin"
      ],
      "sourceUrl": "https://arxiv.org/abs/1706.03762",
      "imageUrl": null,
      "tags": [
        "Transformer",
        "Self-attention"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/1706.03762"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2018_GPT1",
      "title": "GPT introduces generative pretraining for language understanding",
      "description": "Pretrain then adapt. A template for modern foundation models.",
      "date": "2018-01-01",
      "category": "model_release",
      "significance": 3,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Alec Radford"
      ],
      "sourceUrl": "https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf",
      "imageUrl": null,
      "tags": [
        "Pretraining",
        "Fine-tuning",
        "Autoregressive LMs"
      ],
      "sources": [
        {
          "label": "Paper (OpenAI)",
          "kind": "paper",
          "url": "https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2018_BERT",
      "title": "BERT popularizes masked language model pretraining",
      "description": "Transforms NLP benchmarks and downstream fine-tuning practice.",
      "date": "2018-01-01",
      "category": "model_release",
      "significance": 2,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Jacob Devlin"
      ],
      "sourceUrl": "https://arxiv.org/abs/1810.04805",
      "imageUrl": null,
      "tags": [
        "Masked language modeling",
        "Transformers"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/1810.04805"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2018_OPENAI_CHARTER",
      "title": "OpenAI Charter published",
      "description": "A defining governance document for OpenAI’s mission and principles.",
      "date": "2018-04-01",
      "category": "regulation",
      "significance": 1,
      "era": "Governance and Institutions",
      "organization": null,
      "contributors": [],
      "sourceUrl": "https://openai.com/charter/",
      "imageUrl": null,
      "tags": [
        "AI governance",
        "Safety"
      ],
      "sources": [
        {
          "label": "OpenAI Charter",
          "kind": "primary_doc",
          "url": "https://openai.com/charter/"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2019_GPT2",
      "title": "GPT-2 release and staged publication debate",
      "description": "Highlights capability scaling and risk discourse around text generation.",
      "date": "2019-01-01",
      "category": "model_release",
      "significance": 1,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Alec Radford"
      ],
      "sourceUrl": "https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf",
      "imageUrl": null,
      "tags": [
        "Autoregressive LMs",
        "Model release strategy"
      ],
      "sources": [
        {
          "label": "Technical report (PDF)",
          "kind": "paper",
          "url": "https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2019_OECD_AI_PRINCIPLES",
      "title": "OECD AI Principles adopted",
      "description": "Influential international principles for trustworthy AI.",
      "date": "2019-05-01",
      "category": "regulation",
      "significance": 1,
      "era": "Governance and Policy",
      "organization": null,
      "contributors": [],
      "sourceUrl": "https://oecd.ai/en/ai-principles",
      "imageUrl": null,
      "tags": [
        "Trustworthy AI",
        "AI policy"
      ],
      "sources": [
        {
          "label": "OECD Principles (official)",
          "kind": "primary_doc",
          "url": "https://oecd.ai/en/ai-principles"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2019_ROBERTA",
      "title": "RoBERTa refines BERT pretraining recipe",
      "description": "Shows how training choices and data scale change outcomes.",
      "date": "2019-07-26",
      "category": "model_release",
      "significance": 2,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Yinhan Liu"
      ],
      "sourceUrl": "https://arxiv.org/abs/1907.11692",
      "imageUrl": null,
      "tags": [
        "Pretraining recipes",
        "Transformers"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/1907.11692"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2019_T5",
      "title": "T5 frames NLP as text-to-text transfer learning",
      "description": "A unifying recipe for multi-task and transfer learning in NLP.",
      "date": "2019-10-23",
      "category": "model_release",
      "significance": 1,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Colin Raffel",
        "Noam Shazeer"
      ],
      "sourceUrl": "https://arxiv.org/abs/1910.10683",
      "imageUrl": null,
      "tags": [
        "Text-to-text",
        "Transfer learning"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/1910.10683"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2020_SCALING_LAWS",
      "title": "Scaling laws for neural language models",
      "description": "Empirical laws connecting loss to compute, data, and parameters.",
      "date": "2020-01-01",
      "category": "model_release",
      "significance": 1,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Jared Kaplan"
      ],
      "sourceUrl": "https://arxiv.org/abs/2001.08361",
      "imageUrl": null,
      "tags": [
        "Scaling laws",
        "Compute"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2001.08361"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2020_RAG",
      "title": "Retrieval-Augmented Generation (RAG) introduced",
      "description": "Combines parametric models with retrieval for factuality and attribution.",
      "date": "2020-01-01",
      "category": "model_release",
      "significance": 1,
      "era": "LLM Techniques",
      "organization": null,
      "contributors": [
        "Patrick Lewis"
      ],
      "sourceUrl": "https://arxiv.org/abs/2005.11401",
      "imageUrl": null,
      "tags": [
        "RAG",
        "Retrieval"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2005.11401"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2020_GPT3",
      "title": "GPT-3 demonstrates strong few-shot learning at scale",
      "description": "Catalyzes the modern foundation-model era.",
      "date": "2020-05-28",
      "category": "model_release",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Tom B. Brown",
        "OpenAI"
      ],
      "sourceUrl": "https://arxiv.org/abs/2005.14165",
      "imageUrl": null,
      "tags": [
        "Few-shot learning",
        "Foundation models"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2005.14165"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2020_GEBRU_FIRING",
      "title": "Google fires AI ethics researcher Timnit Gebru",
      "description": "Google terminates prominent AI ethics co-lead Timnit Gebru after dispute over a research paper about bias in large language models. Over 2,700 Google employees and 4,300 academics sign letter condemning the firing, sparking industry-wide debate about corporate control of AI ethics research.",
      "date": "2020-12-02",
      "category": "cultural",
      "significance": 3,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Timnit Gebru",
        "Google"
      ],
      "sourceUrl": "https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/",
      "imageUrl": null,
      "tags": [
        "AI Ethics",
        "Corporate AI",
        "Diversity in Tech"
      ],
      "sources": [
        {
          "label": "MIT Technology Review",
          "kind": "media",
          "url": "https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/"
        },
        {
          "label": "Washington Post",
          "kind": "media",
          "url": "https://www.washingtonpost.com/technology/2020/12/23/google-timnit-gebru-ai-ethics/"
        }
      ],
      "createdAt": "2025-12-17T23:52:41.291Z",
      "updatedAt": "2025-12-17T23:52:41.291Z"
    },
    {
      "id": "E2021_CLIP",
      "title": "CLIP aligns vision and language with contrastive learning",
      "description": "A major foundation for multimodal retrieval and generation systems.",
      "date": "2021-01-01",
      "category": "model_release",
      "significance": 3,
      "era": "Multimodal",
      "organization": null,
      "contributors": [
        "Alec Radford",
        "OpenAI"
      ],
      "sourceUrl": "https://arxiv.org/abs/2103.00020",
      "imageUrl": null,
      "tags": [
        "Contrastive learning",
        "Vision-language models"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2103.00020"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2021_DALLE",
      "title": "DALL·E demonstrates zero-shot text-to-image generation",
      "description": "Popularizes text-to-image synthesis as a mainstream capability.",
      "date": "2021-01-01",
      "category": "model_release",
      "significance": 2,
      "era": "Multimodal",
      "organization": null,
      "contributors": [
        "OpenAI"
      ],
      "sourceUrl": "https://arxiv.org/abs/2102.12092",
      "imageUrl": null,
      "tags": [
        "Text-to-image",
        "Generative models"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2102.12092"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2021_CODEX",
      "title": "Codex reports strong code generation abilities",
      "description": "A key precursor to code assistants and developer copilots.",
      "date": "2021-01-01",
      "category": "product",
      "significance": 1,
      "era": "Code Models",
      "organization": null,
      "contributors": [
        "Mark Chen",
        "OpenAI"
      ],
      "sourceUrl": "https://arxiv.org/abs/2107.03374",
      "imageUrl": null,
      "tags": [
        "Code generation",
        "LLMs"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2107.03374"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2021_ALPHAFOLD2",
      "title": "AlphaFold achieves highly accurate protein structure prediction",
      "description": "A landmark scientific result showcasing deep learning’s impact beyond NLP and vision.",
      "date": "2021-01-01",
      "category": "research",
      "significance": 3,
      "era": "Scientific AI",
      "organization": null,
      "contributors": [
        "John Jumper",
        "DeepMind"
      ],
      "sourceUrl": "https://www.nature.com/articles/s41586-021-03819-2",
      "imageUrl": null,
      "tags": [
        "Protein folding",
        "Scientific ML"
      ],
      "sources": [
        {
          "label": "Nature paper",
          "kind": "paper",
          "url": "https://www.nature.com/articles/s41586-021-03819-2"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2021_SWITCH_TRANSFORMERS",
      "title": "Switch Transformers scale Mixture-of-Experts models",
      "description": "Sparse routing enables huge parameter counts at lower compute cost.",
      "date": "2021-01-11",
      "category": "model_release",
      "significance": 3,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "William Fedus",
        "Barret Zoph",
        "Noam Shazeer"
      ],
      "sourceUrl": "https://arxiv.org/abs/2101.03961",
      "imageUrl": null,
      "tags": [
        "MoE",
        "Sparse routing"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2101.03961"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2022_LATENT_DIFFUSION",
      "title": "Latent Diffusion Models (foundation of Stable Diffusion) published",
      "description": "Efficient diffusion in latent space enables high-quality image generation.",
      "date": "2021-12-01",
      "category": "model_release",
      "significance": 1,
      "era": "Multimodal",
      "organization": null,
      "contributors": [
        "Robin Rombach",
        "CompVis"
      ],
      "sourceUrl": "https://arxiv.org/abs/2112.10752",
      "imageUrl": null,
      "tags": [
        "Diffusion models",
        "Latent diffusion"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2112.10752"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2022_CHINCHILLA",
      "title": "Chinchilla formalizes compute-optimal training tradeoffs",
      "description": "Argues many LLMs were undertrained on tokens relative to parameter count.",
      "date": "2022-01-01",
      "category": "model_release",
      "significance": 1,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Jordan Hoffmann",
        "DeepMind"
      ],
      "sourceUrl": "https://arxiv.org/abs/2203.15556",
      "imageUrl": null,
      "tags": [
        "Compute-optimal training",
        "Scaling laws"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2203.15556"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2022_INSTRUCTGPT",
      "title": "InstructGPT demonstrates RLHF for instruction-following",
      "description": "A core milestone in aligning LLM behavior to human preferences.",
      "date": "2022-01-01",
      "category": "research",
      "significance": 1,
      "era": "Alignment and Instruction Following",
      "organization": null,
      "contributors": [
        "Long Ouyang",
        "OpenAI"
      ],
      "sourceUrl": "https://arxiv.org/abs/2203.02155",
      "imageUrl": null,
      "tags": [
        "RLHF",
        "Instruction tuning",
        "Alignment"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2203.02155"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2022_CHATGPT",
      "title": "OpenAI launches ChatGPT, reaching 100 million users in 2 months",
      "description": "OpenAI releases ChatGPT, a conversational AI assistant built on GPT-3.5 and fine-tuned using RLHF. Becomes the fastest-growing consumer application in history, reaching 100 million monthly active users by January 2023. Demonstrates that instruction-tuned language models can serve as general-purpose assistants, igniting global interest in AI capabilities and sparking an industry-wide race to develop competing chatbots.",
      "date": "2022-11-30",
      "category": "product_launch",
      "significance": 1,
      "era": "Alignment and Instruction Following",
      "organization": "OpenAI",
      "contributors": [
        "OpenAI"
      ],
      "sourceUrl": "https://openai.com/blog/chatgpt",
      "imageUrl": null,
      "tags": [
        "LLMs",
        "Chatbots",
        "RLHF",
        "Consumer AI"
      ],
      "sources": [
        {
          "label": "OpenAI Blog Announcement",
          "kind": "blog",
          "url": "https://openai.com/blog/chatgpt"
        },
        {
          "label": "Reuters - Fastest Growing App",
          "kind": "media",
          "url": "https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/"
        }
      ],
      "createdAt": "2025-12-17T23:56:00.000Z",
      "updatedAt": "2025-12-17T23:56:00.000Z"
    },
    {
      "id": "E2022_BLOOM",
      "title": "BLOOM released as a large open-access multilingual LM",
      "description": "A major collaborative effort to broaden access to large-scale language models.",
      "date": "2022-01-01",
      "category": "model_release",
      "significance": 1,
      "era": "Open Models",
      "organization": null,
      "contributors": [
        "BigScience Workshop"
      ],
      "sourceUrl": "https://arxiv.org/abs/2211.05100",
      "imageUrl": null,
      "tags": [
        "Open models",
        "Multilingual LMs"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2211.05100"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2022_STABLE_DIFFUSION_RELEASE",
      "title": "Stable Diffusion model and code released publicly",
      "description": "Brings strong text-to-image generation into wide public and developer use.",
      "date": "2022-01-01",
      "category": "model_release",
      "significance": 1,
      "era": "Multimodal",
      "organization": null,
      "contributors": [
        "CompVis",
        "Stability AI"
      ],
      "sourceUrl": "https://github.com/CompVis/stable-diffusion",
      "imageUrl": null,
      "tags": [
        "Open weights",
        "Text-to-image"
      ],
      "sources": [
        {
          "label": "Repository (primary)",
          "kind": "code_repo",
          "url": "https://github.com/CompVis/stable-diffusion"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2022_PALM",
      "title": "PaLM scales dense Transformers to 540B parameters",
      "description": "A major public milestone in very large dense language models.",
      "date": "2022-04-05",
      "category": "model_release",
      "significance": 3,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Aakanksha Chowdhery",
        "Google"
      ],
      "sourceUrl": "https://arxiv.org/abs/2204.02311",
      "imageUrl": null,
      "tags": [
        "Scaling",
        "Large language models"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2204.02311"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2023_LLAMA",
      "title": "LLaMA accelerates open foundation model research",
      "description": "Popularizes strong base models usable for fine-tuning and instruction tuning in the open ecosystem.",
      "date": "2023-01-01",
      "category": "model_release",
      "significance": 2,
      "era": "Open Models",
      "organization": null,
      "contributors": [
        "Meta AI"
      ],
      "sourceUrl": "https://arxiv.org/abs/2302.13971",
      "imageUrl": null,
      "tags": [
        "Open models",
        "Fine-tuning"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2302.13971"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2023_NIST_AIRMF",
      "title": "NIST AI Risk Management Framework (AI RMF 1.0) released",
      "description": "A widely used voluntary framework for managing AI risks and trustworthiness.",
      "date": "2023-01-01",
      "category": "regulation",
      "significance": 2,
      "era": "Governance and Policy",
      "organization": null,
      "contributors": [
        "NIST"
      ],
      "sourceUrl": "https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf",
      "imageUrl": null,
      "tags": [
        "Risk management",
        "Trustworthy AI"
      ],
      "sources": [
        {
          "label": "Framework (PDF)",
          "kind": "primary_doc",
          "url": "https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2023_GPT4",
      "title": "GPT-4 technical report published",
      "description": "Documents a large-scale multimodal model and post-training alignment approach.",
      "date": "2023-03-15",
      "category": "model_release",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "OpenAI"
      ],
      "sourceUrl": "https://arxiv.org/abs/2303.08774",
      "imageUrl": null,
      "tags": [
        "Multimodal LLMs",
        "Alignment"
      ],
      "sources": [
        {
          "label": "Technical report (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2303.08774"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2023_PAUSE_AI_LETTER",
      "title": "\"Pause Giant AI Experiments\" open letter calls for 6-month moratorium",
      "description": "Future of Life Institute publishes open letter signed by Elon Musk, Steve Wozniak, and over 30,000 others calling to pause training AI systems more powerful than GPT-4. Letter cites \"profound risks to society and humanity\" and ignites mainstream AI safety debate.",
      "date": "2023-03-22",
      "category": "policy",
      "significance": 3,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Future of Life Institute",
        "Elon Musk",
        "Steve Wozniak",
        "Yoshua Bengio"
      ],
      "sourceUrl": "https://futureoflife.org/open-letter/pause-giant-ai-experiments/",
      "imageUrl": null,
      "tags": [
        "AI Safety",
        "AI Risk",
        "Public Debate",
        "Open Letter"
      ],
      "sources": [
        {
          "label": "Future of Life Institute",
          "kind": "primary_doc",
          "url": "https://futureoflife.org/open-letter/pause-giant-ai-experiments/"
        }
      ],
      "createdAt": "2025-12-17T23:52:41.291Z",
      "updatedAt": "2025-12-17T23:52:41.291Z"
    },
    {
      "id": "E2023_AI_DRAKE_SONG",
      "title": "AI-generated \"Heart on My Sleeve\" mimicking Drake and The Weeknd goes viral",
      "description": "Song by anonymous artist Ghostwriter977 uses AI to mimic Drake and The Weeknd's voices, garnering millions of streams before Universal Music demands removal. Sparks debate about AI in music, artist rights, and creative authenticity. Later submitted for Grammy consideration.",
      "date": "2023-04-04",
      "category": "cultural",
      "significance": 2,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Ghostwriter977"
      ],
      "sourceUrl": "https://variety.com/2023/music/news/fake-ai-generated-drake-weeknd-collaboration-heart-on-my-sleeve-1235585451/",
      "imageUrl": null,
      "tags": [
        "AI Music",
        "Copyright",
        "Viral Moment",
        "Voice Cloning"
      ],
      "sources": [
        {
          "label": "Variety",
          "kind": "media",
          "url": "https://variety.com/2023/music/news/fake-ai-generated-drake-weeknd-collaboration-heart-on-my-sleeve-1235585451/"
        },
        {
          "label": "Billboard",
          "kind": "media",
          "url": "https://www.billboard.com/music/pop/ghostwriter-heart-on-my-sleeve-drake-ai-grammy-exclusive-interview-1235434099/"
        }
      ],
      "createdAt": "2025-12-17T23:52:41.291Z",
      "updatedAt": "2025-12-17T23:52:41.291Z"
    },
    {
      "id": "E2023_HOLLYWOOD_AI_STRIKES",
      "title": "Hollywood writers and actors strike with AI protections as key demand",
      "description": "WGA strikes for 148 days starting May 2, SAG-AFTRA joins July 14 - first joint strike since 1960. AI protections are central demands: limiting AI-written scripts and digital replicas of actors. Results in groundbreaking contract provisions regulating AI use in entertainment.",
      "date": "2023-05-02",
      "category": "cultural",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "WGA",
        "SAG-AFTRA",
        "AMPTP"
      ],
      "sourceUrl": "https://www.equaltimes.org/hollywood-s-stand-against-ai-a",
      "imageUrl": null,
      "tags": [
        "Labor",
        "Entertainment",
        "AI Displacement",
        "Union"
      ],
      "sources": [
        {
          "label": "Wikipedia - SAG-AFTRA Strike",
          "kind": "media",
          "url": "https://en.wikipedia.org/wiki/2023_SAG-AFTRA_strike"
        },
        {
          "label": "Perkins Coie Analysis",
          "kind": "blog",
          "url": "https://perkinscoie.com/insights/blog/generative-ai-movies-and-tv-how-2023-sag-aftra-and-wga-contracts-address-generative"
        }
      ],
      "createdAt": "2025-12-17T23:52:41.291Z",
      "updatedAt": "2025-12-17T23:52:41.291Z"
    },
    {
      "id": "E2023_DPO",
      "title": "Direct Preference Optimization (DPO) simplifies preference-based alignment",
      "description": "An influential alternative to full RLHF pipelines for aligning LMs.",
      "date": "2023-05-29",
      "category": "research",
      "significance": 1,
      "era": "Alignment and Safety",
      "organization": null,
      "contributors": [
        "Rafael Rafailov",
        "Stefano Ermon",
        "Chelsea Finn"
      ],
      "sourceUrl": "https://arxiv.org/abs/2305.18290",
      "imageUrl": null,
      "tags": [
        "Preference optimization",
        "Alignment"
      ],
      "sources": [
        {
          "label": "Paper (arXiv)",
          "kind": "paper",
          "url": "https://arxiv.org/abs/2305.18290"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2023_US_EO_14110",
      "title": "US Executive Order 14110 on AI (Biden) issued",
      "description": "Major US federal policy action focused on safety, security, and trustworthy AI development and use.",
      "date": "2023-10-30",
      "category": "regulation",
      "significance": 1,
      "era": "Governance and Policy",
      "organization": null,
      "contributors": [],
      "sourceUrl": "https://bidenwhitehouse.archives.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/",
      "imageUrl": null,
      "tags": [
        "AI policy",
        "AI safety"
      ],
      "sources": [
        {
          "label": "White House archive (primary)",
          "kind": "primary_doc",
          "url": "https://bidenwhitehouse.archives.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2023_OPENAI_BOARD_CRISIS",
      "title": "OpenAI board fires Sam Altman; he returns as CEO within 5 days",
      "description": "OpenAI's board abruptly fires CEO Sam Altman on November 17, citing lack of candor. Over 95% of employees threaten to quit, Microsoft offers Altman a job, and by November 21 he returns as CEO with a restructured board. Crisis exposes tensions between AI safety governance and commercial pressures.",
      "date": "2023-11-17",
      "category": "cultural",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Sam Altman",
        "OpenAI Board",
        "Ilya Sutskever",
        "Microsoft"
      ],
      "sourceUrl": "https://techcrunch.com/2024/01/05/a-timeline-of-sam-altmans-firing-from-openai-and-the-fallout/",
      "imageUrl": null,
      "tags": [
        "Corporate Drama",
        "AI Governance",
        "OpenAI",
        "Silicon Valley"
      ],
      "sources": [
        {
          "label": "TechCrunch Timeline",
          "kind": "media",
          "url": "https://techcrunch.com/2024/01/05/a-timeline-of-sam-altmans-firing-from-openai-and-the-fallout/"
        },
        {
          "label": "Wikipedia",
          "kind": "media",
          "url": "https://en.wikipedia.org/wiki/Removal_of_Sam_Altman_from_OpenAI"
        }
      ],
      "createdAt": "2025-12-17T23:52:41.291Z",
      "updatedAt": "2025-12-17T23:52:41.291Z"
    },
    {
      "id": "E2024_EU_AI_ACT",
      "title": "EU AI Act becomes law (Regulation (EU) 2024/1689)",
      "description": "A comprehensive risk-based framework for AI systems in the EU.",
      "date": "2024-01-01",
      "category": "regulation",
      "significance": 1,
      "era": "Governance and Policy",
      "organization": null,
      "contributors": [],
      "sourceUrl": "https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=OJ%3AL_202401689",
      "imageUrl": null,
      "tags": [
        "AI regulation",
        "Risk-based governance"
      ],
      "sources": [
        {
          "label": "EUR-Lex PDF endpoint (may require JS)",
          "kind": "primary_doc",
          "url": "https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=OJ%3AL_202401689"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2024_GEMINI_1_5_PRO",
      "title": "Google releases Gemini 1.5 Pro with 1M token context window",
      "description": "Google introduces Gemini 1.5 Pro with groundbreaking 1 million token context window, using Mixture-of-Experts architecture. Can process 11 hours of audio, 1 hour of video, or 700,000 words in a single pass.",
      "date": "2024-02-15",
      "category": "model_release",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Google DeepMind"
      ],
      "sourceUrl": "https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/",
      "imageUrl": null,
      "tags": [
        "Multimodal",
        "Long context",
        "Mixture of Experts"
      ],
      "sources": [
        {
          "label": "Google Blog Announcement",
          "kind": "blog",
          "url": "https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/"
        }
      ],
      "createdAt": "2025-12-17T22:19:50.970Z",
      "updatedAt": "2025-12-17T22:19:50.970Z"
    },
    {
      "id": "E2024_SORA_PREVIEW",
      "title": "OpenAI previews Sora text-to-video model",
      "description": "OpenAI announces Sora, a diffusion model capable of generating photorealistic videos up to one minute long from text prompts. Demonstrates understanding of physical world dynamics and object permanence.",
      "date": "2024-02-15",
      "category": "model_release",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "OpenAI"
      ],
      "sourceUrl": "https://openai.com/sora",
      "imageUrl": null,
      "tags": [
        "Text-to-video",
        "Diffusion models",
        "Generative AI"
      ],
      "sources": [
        {
          "label": "OpenAI Sora Page",
          "kind": "blog",
          "url": "https://openai.com/sora"
        }
      ],
      "createdAt": "2025-12-17T22:19:50.970Z",
      "updatedAt": "2025-12-17T22:19:50.970Z"
    },
    {
      "id": "E2024_CLAUDE_3",
      "title": "Anthropic releases Claude 3 model family (Opus, Sonnet, Haiku)",
      "description": "Anthropic launches Claude 3 with three models setting new benchmarks in reasoning, math, coding, and vision. Claude 3 Opus achieves near-human comprehension on complex tasks and introduces multimodal capabilities.",
      "date": "2024-03-04",
      "category": "model_release",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Anthropic"
      ],
      "sourceUrl": "https://www.anthropic.com/news/claude-3-family",
      "imageUrl": null,
      "tags": [
        "Multimodal",
        "LLM",
        "AI Safety"
      ],
      "sources": [
        {
          "label": "Anthropic Announcement",
          "kind": "blog",
          "url": "https://www.anthropic.com/news/claude-3-family"
        }
      ],
      "createdAt": "2025-12-17T22:19:50.970Z",
      "updatedAt": "2025-12-17T22:19:50.970Z"
    },
    {
      "id": "E2024_LLAMA_3",
      "title": "Meta releases Llama 3 open-weight models",
      "description": "Meta releases Llama 3 in 8B and 70B parameter sizes, trained on 15 trillion tokens. Open-weight release enables widespread AI development and fine-tuning without massive compute requirements.",
      "date": "2024-04-18",
      "category": "model_release",
      "significance": 3,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Meta AI"
      ],
      "sourceUrl": "https://ai.meta.com/blog/meta-llama-3/",
      "imageUrl": null,
      "tags": [
        "Open source",
        "LLM",
        "Democratization"
      ],
      "sources": [
        {
          "label": "Meta AI Blog",
          "kind": "blog",
          "url": "https://ai.meta.com/blog/meta-llama-3/"
        }
      ],
      "createdAt": "2025-12-17T22:19:50.970Z",
      "updatedAt": "2025-12-17T22:19:50.970Z"
    },
    {
      "id": "E2024_GPT4O",
      "title": "OpenAI releases GPT-4o omni model with native multimodal capabilities",
      "description": "OpenAI launches GPT-4o (omni), accepting any combination of text, audio, image, and video inputs. Responds to audio in 232ms average, matching human conversation speed. Made free for all ChatGPT users.",
      "date": "2024-05-13",
      "category": "model_release",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "OpenAI"
      ],
      "sourceUrl": "https://openai.com/index/hello-gpt-4o/",
      "imageUrl": null,
      "tags": [
        "Multimodal",
        "Voice AI",
        "Real-time"
      ],
      "sources": [
        {
          "label": "OpenAI Announcement",
          "kind": "blog",
          "url": "https://openai.com/index/hello-gpt-4o/"
        }
      ],
      "createdAt": "2025-12-17T22:19:50.970Z",
      "updatedAt": "2025-12-17T22:19:50.970Z"
    },
    {
      "id": "E2024_SCARLETT_JOHANSSON_SKY",
      "title": "Scarlett Johansson threatens legal action over ChatGPT \"Sky\" voice",
      "description": "Actress Scarlett Johansson publicly criticizes OpenAI after ChatGPT's \"Sky\" voice sounds eerily similar to her - after she declined to voice the assistant. OpenAI pauses the voice. CEO Sam Altman's \"her\" tweet referencing the film intensifies controversy over AI and celebrity likeness rights.",
      "date": "2024-05-20",
      "category": "cultural",
      "significance": 3,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Scarlett Johansson",
        "Sam Altman",
        "OpenAI"
      ],
      "sourceUrl": "https://www.npr.org/2024/05/20/1252495087/openai-pulls-ai-voice-that-was-compared-to-scarlett-johansson-in-the-movie-her",
      "imageUrl": null,
      "tags": [
        "AI Voice",
        "Celebrity Rights",
        "OpenAI",
        "Right of Publicity"
      ],
      "sources": [
        {
          "label": "NPR",
          "kind": "media",
          "url": "https://www.npr.org/2024/05/20/1252495087/openai-pulls-ai-voice-that-was-compared-to-scarlett-johansson-in-the-movie-her"
        },
        {
          "label": "Washington Post",
          "kind": "media",
          "url": "https://www.washingtonpost.com/technology/2024/05/20/openai-scarlett-johansson-chatgpt-ai-voice/"
        }
      ],
      "createdAt": "2025-12-17T23:52:41.291Z",
      "updatedAt": "2025-12-17T23:52:41.291Z"
    },
    {
      "id": "E2024_APPLE_INTELLIGENCE",
      "title": "Apple announces Apple Intelligence at WWDC",
      "description": "Apple introduces Apple Intelligence, integrating generative AI into iOS 18, iPadOS 18, and macOS Sequoia. Features on-device processing with Private Cloud Compute and ChatGPT integration for Siri.",
      "date": "2024-06-10",
      "category": "product_launch",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Apple"
      ],
      "sourceUrl": "https://www.apple.com/newsroom/2024/06/introducing-apple-intelligence-for-iphone-ipad-and-mac/",
      "imageUrl": null,
      "tags": [
        "Consumer AI",
        "Privacy",
        "Mobile AI"
      ],
      "sources": [
        {
          "label": "Apple Newsroom",
          "kind": "blog",
          "url": "https://www.apple.com/newsroom/2024/06/introducing-apple-intelligence-for-iphone-ipad-and-mac/"
        }
      ],
      "createdAt": "2025-12-17T22:19:50.970Z",
      "updatedAt": "2025-12-17T22:19:50.970Z"
    },
    {
      "id": "E2024_CLAUDE_3_5_SONNET",
      "title": "Anthropic releases Claude 3.5 Sonnet, outperforming larger models",
      "description": "Anthropic launches Claude 3.5 Sonnet, operating at twice the speed of Claude 3 Opus while outperforming it on benchmarks. Introduces Artifacts feature for real-time code preview and collaboration.",
      "date": "2024-06-20",
      "category": "model_release",
      "significance": 3,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Anthropic"
      ],
      "sourceUrl": "https://www.anthropic.com/news/claude-3-5-sonnet",
      "imageUrl": null,
      "tags": [
        "LLM",
        "Coding",
        "AI Safety"
      ],
      "sources": [
        {
          "label": "Anthropic Announcement",
          "kind": "blog",
          "url": "https://www.anthropic.com/news/claude-3-5-sonnet"
        }
      ],
      "createdAt": "2025-12-17T22:19:50.970Z",
      "updatedAt": "2025-12-17T22:19:50.970Z"
    },
    {
      "id": "E2025_DEEPSEEK_R1",
      "title": "DeepSeek releases R1, disrupting AI industry with efficient training",
      "description": "Chinese AI lab DeepSeek releases DeepSeek-R1, a reasoning model matching OpenAI's o1 performance while trained on far less powerful hardware. The release triggers an 18% drop in Nvidia's stock price and is called a 'Sputnik moment' for American AI. By January 27, DeepSeek surpasses ChatGPT as the most downloaded app on iOS in the US, demonstrating that innovative training approaches can rival massive compute investments.",
      "date": "2025-01-20",
      "category": "model_release",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "DeepSeek"
      ],
      "sourceUrl": "https://api-docs.deepseek.com/news/news250120",
      "imageUrl": null,
      "tags": [
        "Efficient training",
        "Reasoning models",
        "Open weights",
        "AI competition"
      ],
      "sources": [
        {
          "label": "DeepSeek API announcement",
          "kind": "primary_doc",
          "url": "https://api-docs.deepseek.com/news/news250120"
        },
        {
          "label": "Wikipedia",
          "kind": "media",
          "url": "https://en.wikipedia.org/wiki/DeepSeek"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2025_US_EO_14110_REVOKED",
      "title": "US action revokes EO 14110 and shifts federal AI policy posture",
      "description": "A later White House order states EO 14110 was revoked and directs review of actions taken under it.",
      "date": "2025-01-23",
      "category": "regulation",
      "significance": 1,
      "era": "Governance and Policy",
      "organization": null,
      "contributors": [],
      "sourceUrl": "https://www.whitehouse.gov/presidential-actions/2025/01/removing-barriers-to-american-leadership-in-artificial-intelligence/",
      "imageUrl": null,
      "tags": [
        "AI policy",
        "Regulatory shifts"
      ],
      "sources": [
        {
          "label": "White House order (primary)",
          "kind": "primary_doc",
          "url": "https://www.whitehouse.gov/presidential-actions/2025/01/removing-barriers-to-american-leadership-in-artificial-intelligence/"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2025_OPENAI_OPERATOR",
      "title": "OpenAI launches Operator, first major AI agent for autonomous web tasks",
      "description": "OpenAI releases Operator as a research preview, an AI agent powered by the Computer-Using Agent (CUA) model that can autonomously browse the web to accomplish tasks like booking tickets, filling grocery orders, and conducting research. Combines GPT-4o's vision capabilities with reinforcement learning to interact with graphical user interfaces. Available to ChatGPT Pro subscribers at $200/month, later integrated into ChatGPT as 'agent mode'.",
      "date": "2025-01-23",
      "category": "product",
      "significance": 1,
      "era": "AI Agents",
      "organization": null,
      "contributors": [
        "OpenAI"
      ],
      "sourceUrl": "https://openai.com/index/introducing-operator/",
      "imageUrl": null,
      "tags": [
        "AI agents",
        "Computer use",
        "Autonomous AI",
        "Web automation"
      ],
      "sources": [
        {
          "label": "OpenAI announcement",
          "kind": "primary_doc",
          "url": "https://openai.com/index/introducing-operator/"
        },
        {
          "label": "MIT Technology Review",
          "kind": "media",
          "url": "https://www.technologyreview.com/2025/01/23/1110484/openai-launches-operator-an-agent-that-can-use-a-computer-for-you/"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2025_GROK_3",
      "title": "xAI releases Grok 3 with 10x compute and 1M token context",
      "description": "Elon Musk's xAI releases Grok 3, trained with 10x more compute than Grok 2 using the Colossus data center with ~200,000 GPUs. Features 1 million token context window (8x larger than previous models), reasoning variants that 'think through' problems, DeepSearch for internet and X analysis, and image generation. Musk calls it 'the smartest AI on Earth.' X raises Premium+ subscription to $40/month following launch.",
      "date": "2025-02-17",
      "category": "model_release",
      "significance": 3,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Elon Musk",
        "xAI"
      ],
      "sourceUrl": "https://x.ai/news/grok-3",
      "imageUrl": null,
      "tags": [
        "Large context windows",
        "Reasoning models",
        "AI competition"
      ],
      "sources": [
        {
          "label": "xAI announcement",
          "kind": "primary_doc",
          "url": "https://x.ai/news/grok-3"
        },
        {
          "label": "TechCrunch article",
          "kind": "media",
          "url": "https://techcrunch.com/2025/02/17/elon-musks-ai-company-xai-releases-its-latest-flagship-ai-grok-3/"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2025_CLAUDE_3_7_SONNET",
      "title": "Anthropic releases Claude 3.7 Sonnet with extended thinking",
      "description": "Anthropic introduces Claude 3.7 Sonnet with 'Extended Thinking' mode, allowing the model to reason through complex problems step-by-step before responding. Delivers enhanced coding performance and the ability to analyze its own reasoning processes. The hybrid approach enables both quick responses and deeper reasoning as needed, making it particularly strong for coding, math, and scientific analysis.",
      "date": "2025-02-24",
      "category": "model_release",
      "significance": 1,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Anthropic",
        "Dario Amodei"
      ],
      "sourceUrl": "https://www.anthropic.com/news/claude-3-7-sonnet",
      "imageUrl": null,
      "tags": [
        "Extended thinking",
        "Reasoning models",
        "Chain-of-thought"
      ],
      "sources": [
        {
          "label": "Anthropic announcement",
          "kind": "primary_doc",
          "url": "https://www.anthropic.com/news/claude-3-7-sonnet"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2025_LLAMA_4",
      "title": "Meta releases Llama 4 with mixture-of-experts architecture",
      "description": "Meta releases the Llama 4 model family (Scout, Maverick, Behemoth) - the first Llama models using mixture-of-experts architecture where only a subset of parameters activate per token. Trained on 30+ trillion tokens (2x Llama 3), with Scout offering 10M context window and Maverick 1M context. Llama 4 Behemoth (2T total parameters) outperforms GPT-4.5, Claude Sonnet 3.7, and Gemini 2.0 Pro on STEM benchmarks. Released on a Saturday when CEO Zuckerberg said 'That's when it was ready.'",
      "date": "2025-04-05",
      "category": "model_release",
      "significance": 4,
      "era": "Open Models",
      "organization": null,
      "contributors": [
        "Meta AI",
        "Mark Zuckerberg"
      ],
      "sourceUrl": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/",
      "imageUrl": null,
      "tags": [
        "Mixture-of-experts",
        "Open models",
        "Multimodal AI",
        "Large context windows"
      ],
      "sources": [
        {
          "label": "Meta AI blog",
          "kind": "primary_doc",
          "url": "https://ai.meta.com/blog/llama-4-multimodal-intelligence/"
        },
        {
          "label": "TechCrunch article",
          "kind": "media",
          "url": "https://techcrunch.com/2025/04/05/meta-releases-llama-4-a-new-crop-of-flagship-ai-models/"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2025_DWARKESH_KARPATHY",
      "title": "Dwarkesh Podcast episode with Andrej Karpathy (deep modern overview)",
      "description": "A long-form discussion that works well as an educational resource node in the timeline.",
      "date": "2025-10-17",
      "category": "research",
      "significance": 1,
      "era": "Modern Discourse and Learning Resources",
      "organization": null,
      "contributors": [
        "Dwarkesh Patel",
        "Andrej Karpathy"
      ],
      "sourceUrl": "https://www.dwarkesh.com/p/andrej-karpathy",
      "imageUrl": null,
      "tags": [
        "LLMs",
        "Agents",
        "Modern AI practice"
      ],
      "sources": [
        {
          "label": "Episode page (primary)",
          "kind": "media",
          "url": "https://www.dwarkesh.com/p/andrej-karpathy"
        },
        {
          "label": "YouTube (primary)",
          "kind": "media",
          "url": "https://www.youtube.com/watch?v=lXUZvyajciY"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2025_GEMINI_3",
      "title": "Google releases Gemini 3 Pro with record benchmark scores",
      "description": "Google launches Gemini 3 Pro, described as their best model for multimodal understanding and most powerful agentic and coding model to date. Powers Google Search and the Gemini app. Part of an unprecedented 25-day sprint where four major AI companies released frontier models. Also releases reimagined Gemini Deep Research agent built on Gemini 3 Pro foundation.",
      "date": "2025-11-18",
      "category": "model_release",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Google",
        "DeepMind"
      ],
      "sourceUrl": "https://blog.google/technology/ai/google-ai-updates-november-2025/",
      "imageUrl": null,
      "tags": [
        "Multimodal AI",
        "AI agents",
        "Foundation models"
      ],
      "sources": [
        {
          "label": "Google AI blog",
          "kind": "primary_doc",
          "url": "https://blog.google/technology/ai/google-ai-updates-november-2025/"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2025_CLAUDE_OPUS_4_5",
      "title": "Anthropic releases Claude Opus 4.5 with elite coding performance",
      "description": "Anthropic launches Claude Opus 4.5, delivering elite coding and agentic performance at 67% reduced pricing compared to previous frontier models. Achieves 80.9% accuracy on SWE-bench Verified, outperforming OpenAI's GPT-5.1-Codex-Max (77.9%) and Google's Gemini 3 Pro (76.2%). Makes frontier AI performance accessible at scale, accelerating the agentic AI market projected to grow from $7.38B (2025) to $103.6B by 2032.",
      "date": "2025-11-24",
      "category": "model_release",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Anthropic",
        "Dario Amodei"
      ],
      "sourceUrl": "https://www.anthropic.com/news/claude-opus-4-5",
      "imageUrl": null,
      "tags": [
        "Coding AI",
        "AI agents",
        "Frontier models",
        "Alignment"
      ],
      "sources": [
        {
          "label": "Anthropic announcement",
          "kind": "primary_doc",
          "url": "https://www.anthropic.com/news/claude-opus-4-5"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2025_STARCLOUD_SPACE_AI",
      "title": "Starcloud trains first AI model in space with Nvidia H100 GPU",
      "description": "Nvidia-backed Starcloud becomes first to train and run AI models in orbit, operating NanoGPT (trained on Shakespeare) and Google's Gemma LLM on an H100 GPU aboard its Starcloud-1 satellite. Demonstrates viability of orbital data centers that could alleviate Earth's digital infrastructure constraints with 10x lower energy costs and unlimited solar power.",
      "date": "2025-12-10",
      "category": "industry",
      "significance": 3,
      "era": "Infrastructure and Deployment",
      "organization": null,
      "contributors": [
        "Philip Johnston",
        "Nvidia"
      ],
      "sourceUrl": "https://www.cnbc.com/2025/12/10/nvidia-starcloud-trains-first-ai-model-in-space.html",
      "imageUrl": null,
      "tags": [
        "Orbital data centers",
        "AI infrastructure",
        "Space computing",
        "GPU compute"
      ],
      "sources": [
        {
          "label": "CNBC article (primary)",
          "kind": "media",
          "url": "https://www.cnbc.com/2025/12/10/nvidia-starcloud-trains-first-ai-model-in-space.html"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2025_GPT_5_2",
      "title": "OpenAI releases GPT-5.2, their 'best model for everyday professional use'",
      "description": "OpenAI releases GPT-5.2 (codenamed 'Garlic'), positioned as their best model for everyday professional use. Powers ChatGPT and is available through the API. Released on the same day Google announced Gemini Deep Research updates, marking continued 'code red' competition between the companies. Claims to outperform rivals on standard benchmarks. Powers the subsequently released GPT Image 1.5.",
      "date": "2025-12-11",
      "category": "model_release",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "OpenAI",
        "Sam Altman"
      ],
      "sourceUrl": "https://techcrunch.com/2025/12/11/google-launched-its-deepest-ai-research-agent-yet-on-the-same-day-openai-dropped-gpt-5-2/",
      "imageUrl": null,
      "tags": [
        "Large language models",
        "Foundation models",
        "AI competition"
      ],
      "sources": [
        {
          "label": "TechCrunch article",
          "kind": "media",
          "url": "https://techcrunch.com/2025/12/11/google-launched-its-deepest-ai-research-agent-yet-on-the-same-day-openai-dropped-gpt-5-2/"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2025_GPT_IMAGE_1_5",
      "title": "OpenAI releases GPT Image 1.5 with 4x faster generation",
      "description": "OpenAI launches GPT Image 1.5, delivering 4x faster image generation, significantly improved text rendering in images, and precise editing capabilities that maintain consistency in lighting, composition, and facial likeness across modifications. Available to all ChatGPT users and via API at 20% reduced cost, with a new creative studio interface. Powered by GPT 5.2 and tops independent benchmarks with 1264 points on the Artificial Analysis leaderboard.",
      "date": "2025-12-16",
      "category": "model_release",
      "significance": 1,
      "era": "Multimodal",
      "organization": null,
      "contributors": [
        "OpenAI",
        "Sam Altman"
      ],
      "sourceUrl": "https://openai.com/index/new-chatgpt-images-is-here/",
      "imageUrl": null,
      "tags": [
        "Text-to-image",
        "Image generation",
        "Multimodal AI",
        "Generative models"
      ],
      "sources": [
        {
          "label": "OpenAI announcement",
          "kind": "primary_doc",
          "url": "https://openai.com/index/new-chatgpt-images-is-here/"
        },
        {
          "label": "TechCrunch article",
          "kind": "media",
          "url": "https://techcrunch.com/2025/12/16/openai-continues-on-its-code-red-warpath-with-new-image-generation-model/"
        }
      ],
      "createdAt": "2025-12-17T14:15:41.061Z",
      "updatedAt": "2025-12-17T14:15:41.061Z"
    },
    {
      "id": "E2020_GPT3_API",
      "title": "OpenAI launches GPT-3 API, democratizing access to large language models",
      "description": "OpenAI releases GPT-3 as an API, allowing any developer to access the 175 billion parameter language model through simple HTTP requests. This marks the beginning of the AI-as-a-service era, enabling startups to build AI products without ML expertise or infrastructure. Pay-per-use pricing model established the economics of modern AI services.",
      "date": "2020-06-11",
      "category": "product",
      "significance": 4,
      "era": "Transformers and LLMs",
      "organization": "OpenAI",
      "contributors": [
        "OpenAI",
        "Sam Altman"
      ],
      "sourceUrl": "https://openai.com/blog/openai-api",
      "imageUrl": null,
      "tags": [
        "API",
        "Large language models",
        "AI-as-a-service",
        "GPT-3"
      ],
      "sources": [
        {
          "label": "OpenAI API announcement",
          "kind": "primary_doc",
          "url": "https://openai.com/blog/openai-api"
        }
      ],
      "createdAt": "2025-12-18T00:20:00.000Z",
      "updatedAt": "2025-12-18T00:20:00.000Z"
    },
    {
      "id": "E2021_COPILOT",
      "title": "GitHub launches Copilot, AI pair programming assistant",
      "description": "GitHub releases Copilot, an AI coding assistant powered by OpenAI Codex that suggests code completions in real-time. Trained on public code repositories, it understands context from comments, function names, and surrounding code. Marks the beginning of AI-assisted software development becoming mainstream.",
      "date": "2021-06-29",
      "category": "product",
      "significance": 3,
      "era": "Transformers and LLMs",
      "organization": "GitHub",
      "contributors": [
        "GitHub",
        "OpenAI",
        "Microsoft"
      ],
      "sourceUrl": "https://github.blog/2021-06-29-introducing-github-copilot-ai-pair-programmer/",
      "imageUrl": null,
      "tags": [
        "Code generation",
        "Developer tools",
        "AI copilot",
        "Codex"
      ],
      "sources": [
        {
          "label": "GitHub Copilot announcement",
          "kind": "primary_doc",
          "url": "https://github.blog/2021-06-29-introducing-github-copilot-ai-pair-programmer/"
        }
      ],
      "createdAt": "2025-12-18T00:20:00.000Z",
      "updatedAt": "2025-12-18T00:20:00.000Z"
    },
    {
      "id": "E2023_ENTERPRISE_AI",
      "title": "Enterprise AI wave: Microsoft, Google, AWS integrate LLMs into business software",
      "description": "Major cloud providers integrate large language models into enterprise software stacks. Microsoft launches Copilot for Microsoft 365, Google introduces Duet AI for Workspace, and AWS expands Bedrock. Enterprise AI becomes table stakes as businesses rush to adopt AI following ChatGPT's success.",
      "date": "2023-03-16",
      "category": "industry",
      "significance": 3,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Microsoft",
        "Google",
        "Amazon"
      ],
      "sourceUrl": "https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/",
      "imageUrl": null,
      "tags": [
        "Enterprise AI",
        "Microsoft 365 Copilot",
        "Duet AI",
        "AWS Bedrock"
      ],
      "sources": [
        {
          "label": "Microsoft 365 Copilot announcement",
          "kind": "primary_doc",
          "url": "https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/"
        }
      ],
      "createdAt": "2025-12-18T00:20:00.000Z",
      "updatedAt": "2025-12-18T00:20:00.000Z"
    },
    {
      "id": "E2024_AI_AGENTS",
      "title": "AI agents emerge as production-ready technology for autonomous task completion",
      "description": "AI agents—systems that combine LLMs with tool use and planning capabilities—mature from research demos to production deployments. Frameworks like LangChain, CrewAI, and AutoGen enable businesses to build agents that take actions, use tools, and complete multi-step tasks autonomously.",
      "date": "2024-01-15",
      "category": "breakthrough",
      "significance": 3,
      "era": "AI Agents",
      "organization": null,
      "contributors": [
        "LangChain",
        "OpenAI",
        "Anthropic"
      ],
      "sourceUrl": "https://www.langchain.com/langgraph",
      "imageUrl": null,
      "tags": [
        "AI agents",
        "Autonomous AI",
        "Tool use",
        "LangChain"
      ],
      "sources": [
        {
          "label": "LangGraph announcement",
          "kind": "primary_doc",
          "url": "https://www.langchain.com/langgraph"
        }
      ],
      "createdAt": "2025-12-18T00:20:00.000Z",
      "updatedAt": "2025-12-18T00:20:00.000Z"
    },
    {
      "id": "E2024_RAG_ADOPTION",
      "title": "RAG becomes the standard architecture for enterprise AI knowledge systems",
      "description": "Retrieval-Augmented Generation (RAG) emerges as the dominant pattern for connecting LLMs to enterprise data. Vector databases like Pinecone, Weaviate, and pgvector see widespread adoption as companies build AI systems that can answer questions using their proprietary documents without fine-tuning.",
      "date": "2024-01-01",
      "category": "industry",
      "significance": 3,
      "era": "Transformers and LLMs",
      "organization": null,
      "contributors": [
        "Pinecone",
        "Weaviate",
        "LangChain"
      ],
      "sourceUrl": "https://www.pinecone.io/learn/retrieval-augmented-generation/",
      "imageUrl": null,
      "tags": [
        "RAG",
        "Vector databases",
        "Enterprise AI",
        "Knowledge retrieval"
      ],
      "sources": [
        {
          "label": "Pinecone RAG guide",
          "kind": "article",
          "url": "https://www.pinecone.io/learn/retrieval-augmented-generation/"
        }
      ],
      "createdAt": "2025-12-18T00:20:00.000Z",
      "updatedAt": "2025-12-18T00:20:00.000Z"
    },
    {
      "id": "E2026_WHERE_WE_GO_NEXT",
      "title": "Where Do We Go Next?",
      "description": "A deep exploration of AI's possible futures through three scenarios—optimistic, neutral, and concerning—featuring real perspectives from industry leaders like Dario Amodei, Sam Altman, Geoffrey Hinton, Yann LeCun, and Andrej Karpathy. This milestone synthesizes predictions from Anthropic's 'Machines of Loving Grace,' the 'Situational Awareness' report, and interviews with key AI researchers to map possible trajectories for artificial intelligence development.",
      "date": "2026-12-31",
      "category": "breakthrough",
      "significance": 4,
      "era": "Multimodal & Deployment",
      "organization": "AI Timeline Atlas",
      "contributors": [
        "Dario Amodei",
        "Sam Altman",
        "Geoffrey Hinton",
        "Yann LeCun",
        "Andrej Karpathy",
        "Ilya Sutskever",
        "Leopold Aschenbrenner",
        "Jensen Huang"
      ],
      "sourceUrl": "https://www.darioamodei.com/essay/machines-of-loving-grace",
      "imageUrl": null,
      "tags": [
        "Future Scenarios",
        "AGI",
        "AI Safety",
        "Predictions",
        "Industry Perspectives"
      ],
      "sources": [
        {
          "label": "Machines of Loving Grace",
          "kind": "article",
          "url": "https://www.darioamodei.com/essay/machines-of-loving-grace"
        },
        {
          "label": "Situational Awareness",
          "kind": "article",
          "url": "https://situational-awareness.ai/"
        },
        {
          "label": "Sam Altman Reflections",
          "kind": "article",
          "url": "https://blog.samaltman.com/reflections"
        },
        {
          "label": "Hinton Nobel Speech",
          "kind": "media",
          "url": "https://www.nobelprize.org/prizes/physics/2024/hinton/speech/"
        }
      ],
      "createdAt": "2025-12-18T15:20:00.000Z",
      "updatedAt": "2025-12-18T15:20:00.000Z"
    }
  ],
  "pagination": {
    "page": 1,
    "limit": 75,
    "total": 76,
    "totalPages": 1
  }
}
