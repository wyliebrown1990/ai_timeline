[
  {
    "id": "cp-chatgpt-1",
    "title": "Understanding Transformers",
    "pathId": "chatgpt-story",
    "afterMilestoneId": "E2017_TRANSFORMER",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-transformer-year",
        "question": "In what year was the Transformer architecture introduced?",
        "options": ["2015", "2016", "2017", "2018"],
        "correctIndex": 2,
        "explanation": "The Transformer was introduced in 2017 in the paper 'Attention Is All You Need' by Vaswani et al. at Google."
      },
      {
        "type": "multiple_choice",
        "id": "q-transformer-key",
        "question": "What is the key innovation of the Transformer architecture?",
        "options": [
          "Using more layers than previous models",
          "Processing sequences in parallel using attention",
          "Being smaller and faster than RNNs",
          "Using images instead of text"
        ],
        "correctIndex": 1,
        "explanation": "The Transformer's key innovation is using self-attention to process all parts of a sequence simultaneously, rather than one step at a time like RNNs."
      }
    ]
  },
  {
    "id": "cp-chatgpt-2",
    "title": "The GPT Evolution",
    "pathId": "chatgpt-story",
    "afterMilestoneId": "E2020_GPT3",
    "questions": [
      {
        "type": "ordering",
        "id": "q-gpt-timeline",
        "prompt": "Put these AI milestones in chronological order:",
        "items": [
          {"id": "gpt1", "label": "GPT-1", "date": "2018"},
          {"id": "transformer", "label": "Transformer", "date": "2017"},
          {"id": "gpt3", "label": "GPT-3", "date": "2020"},
          {"id": "gpt2", "label": "GPT-2", "date": "2019"}
        ],
        "correctOrder": ["transformer", "gpt1", "gpt2", "gpt3"]
      },
      {
        "type": "matching",
        "id": "q-gpt-params",
        "prompt": "Match each GPT version with its approximate parameter count:",
        "pairs": [
          {"id": "p1", "left": "GPT-1", "right": "117 million"},
          {"id": "p2", "left": "GPT-2", "right": "1.5 billion"},
          {"id": "p3", "left": "GPT-3", "right": "175 billion"}
        ]
      }
    ]
  },
  {
    "id": "cp-chatgpt-3",
    "title": "ChatGPT and RLHF",
    "pathId": "chatgpt-story",
    "afterMilestoneId": "E2022_CHATGPT",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-rlhf-purpose",
        "question": "What is the main purpose of RLHF (Reinforcement Learning from Human Feedback)?",
        "options": [
          "To make models faster",
          "To align model behavior with human preferences",
          "To reduce the number of parameters",
          "To enable image processing"
        ],
        "correctIndex": 1,
        "explanation": "RLHF trains models to produce outputs that humans rate as more helpful, honest, and harmless, aligning AI behavior with human values."
      },
      {
        "type": "multiple_choice",
        "id": "q-chatgpt-release",
        "question": "What made ChatGPT different from GPT-3 when it launched?",
        "options": [
          "It was much larger",
          "It was trained with RLHF to be conversational and safe",
          "It could process images",
          "It was open source"
        ],
        "correctIndex": 1,
        "explanation": "ChatGPT was built on GPT-3.5 but trained with RLHF (via InstructGPT techniques) to have natural conversations while refusing harmful requests."
      },
      {
        "type": "explain_back",
        "id": "q-explain-chatgpt",
        "concept": "ChatGPT's breakthrough significance",
        "prompt": "In your own words, explain why ChatGPT was such a breakthrough when it launched in November 2022.",
        "rubric": "A good explanation should mention: 1) ChatGPT combined a powerful language model with RLHF training for natural conversation, 2) It was freely accessible and user-friendly, making advanced AI available to everyone, 3) It could have back-and-forth conversations while refusing harmful requests. Credit for mentioning the rapid user adoption or comparison to previous AI assistants."
      }
    ]
  },
  {
    "id": "cp-fundamentals-1",
    "title": "Neural Network Foundations",
    "pathId": "ai-fundamentals",
    "afterMilestoneId": "E1958_PERCEPTRON",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-perceptron-concept",
        "question": "What was the perceptron designed to model?",
        "options": [
          "A single neuron in the brain",
          "The entire human brain",
          "A computer memory chip",
          "A calculator"
        ],
        "correctIndex": 0,
        "explanation": "The perceptron was an early attempt to model a single biological neuron, taking multiple inputs and producing a single output based on learned weights."
      },
      {
        "type": "multiple_choice",
        "id": "q-mcculloch-pitts",
        "question": "What did the McCulloch-Pitts paper (1943) establish?",
        "options": [
          "The first chatbot",
          "That neural computation is mathematically possible",
          "The internet protocol",
          "Deep learning algorithms"
        ],
        "correctIndex": 1,
        "explanation": "McCulloch and Pitts showed that networks of simple artificial neurons could, in principle, compute any logical function, establishing the theoretical foundation for neural networks."
      }
    ]
  },
  {
    "id": "cp-fundamentals-2",
    "title": "The Learning Breakthrough",
    "pathId": "ai-fundamentals",
    "afterMilestoneId": "E1986_BACKPROP",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-backprop-purpose",
        "question": "What problem does backpropagation solve?",
        "options": [
          "Making networks faster",
          "Teaching networks with multiple layers to learn",
          "Compressing data",
          "Connecting to the internet"
        ],
        "correctIndex": 1,
        "explanation": "Backpropagation allows error signals to flow backward through multiple layers, telling each connection how to adjust to improve the network's performance."
      },
      {
        "type": "ordering",
        "id": "q-early-ai-timeline",
        "prompt": "Put these early AI milestones in order:",
        "items": [
          {"id": "perceptron", "label": "Perceptron", "date": "1958"},
          {"id": "mcculloch", "label": "McCulloch-Pitts Paper", "date": "1943"},
          {"id": "backprop", "label": "Backpropagation", "date": "1986"},
          {"id": "eliza", "label": "ELIZA chatbot", "date": "1966"}
        ],
        "correctOrder": ["mcculloch", "perceptron", "eliza", "backprop"]
      }
    ]
  },
  {
    "id": "cp-fundamentals-3",
    "title": "Deep Learning Revolution",
    "pathId": "ai-fundamentals",
    "afterMilestoneId": "E2012_ALEXNET",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-alexnet-impact",
        "question": "Why was AlexNet (2012) considered revolutionary?",
        "options": [
          "It was the first neural network ever",
          "It dramatically outperformed traditional methods on image recognition",
          "It could generate text",
          "It was open source"
        ],
        "correctIndex": 1,
        "explanation": "AlexNet reduced ImageNet error rates by nearly half compared to traditional methods, proving that deep learning could solve real problems and sparking the deep learning revolution."
      },
      {
        "type": "multiple_choice",
        "id": "q-deep-learning-why",
        "question": "What combination made deep learning practical by 2012?",
        "options": [
          "Better scientists and bigger labs",
          "Big data, GPUs, and better algorithms",
          "Government funding and quantum computers",
          "Faster internet connections"
        ],
        "correctIndex": 1,
        "explanation": "The deep learning revolution was enabled by the availability of large datasets (like ImageNet), powerful GPU computing, and algorithmic improvements like better initialization and activation functions."
      },
      {
        "type": "explain_back",
        "id": "q-explain-deep-learning",
        "concept": "Deep learning vs. earlier neural networks",
        "prompt": "Explain in simple terms what makes 'deep' learning different from earlier neural networks.",
        "rubric": "A good explanation should cover: 1) Deep learning uses many layers (hence 'deep'), unlike earlier 1-2 layer networks, 2) Deep networks learn hierarchical features - from simple (edges) to complex (objects), 3) This enables solving harder problems like image recognition or language understanding. Bonus for mentioning the computational requirements or specific breakthroughs."
      }
    ]
  },
  {
    "id": "cp-fundamentals-4",
    "title": "Generative AI",
    "pathId": "ai-fundamentals",
    "afterMilestoneId": "E2014_GANS",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-gan-concept",
        "question": "How do GANs (Generative Adversarial Networks) learn to generate realistic images?",
        "options": [
          "By copying existing images exactly",
          "Through competition between a generator and discriminator",
          "By following human-written rules",
          "By connecting to image databases"
        ],
        "correctIndex": 1,
        "explanation": "GANs use two networks that compete: one generates fake images while the other tries to detect fakes. This adversarial training pushes the generator to produce increasingly realistic outputs."
      },
      {
        "type": "matching",
        "id": "q-nn-architectures",
        "prompt": "Match each architecture to what it's best at:",
        "pairs": [
          {"id": "p1", "left": "CNN", "right": "Image recognition"},
          {"id": "p2", "left": "GAN", "right": "Image generation"},
          {"id": "p3", "left": "Transformer", "right": "Language understanding"}
        ]
      }
    ]
  },
  {
    "id": "cp-governance-1",
    "title": "AI Ethics and Safety",
    "pathId": "ai-governance",
    "afterMilestoneId": "E2022_CONSTITUTIONAL_AI",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-constitutional-ai",
        "question": "What is Constitutional AI's approach to making AI safer?",
        "options": [
          "Limiting AI to simple tasks only",
          "Using a set of principles for AI to self-critique and improve",
          "Having humans review every AI output",
          "Making AI models smaller"
        ],
        "correctIndex": 1,
        "explanation": "Constitutional AI gives the model a set of principles (a 'constitution') and trains it to critique and revise its own outputs according to those principles, making safety more scalable."
      },
      {
        "type": "multiple_choice",
        "id": "q-rlhf-vs-cai",
        "question": "How does Constitutional AI differ from standard RLHF?",
        "options": [
          "It doesn't use any human feedback",
          "It uses explicit principles for AI self-improvement, reducing human labeling needs",
          "It makes models larger",
          "It only works for images"
        ],
        "correctIndex": 1,
        "explanation": "While RLHF relies heavily on human raters, Constitutional AI uses explicit principles that the AI applies to critique its own outputs, making the alignment process more transparent and scalable."
      }
    ]
  },
  {
    "id": "cp-governance-2",
    "title": "AI Regulation Landscape",
    "pathId": "ai-governance",
    "afterMilestoneId": "E2024_EU_AI_ACT",
    "questions": [
      {
        "type": "ordering",
        "id": "q-regulation-timeline",
        "prompt": "Put these AI governance milestones in chronological order:",
        "items": [
          {"id": "openai-charter", "label": "OpenAI Charter", "date": "2018"},
          {"id": "oecd", "label": "OECD AI Principles", "date": "2019"},
          {"id": "nist", "label": "NIST AI Risk Management Framework", "date": "2023"},
          {"id": "eu-act", "label": "EU AI Act", "date": "2024"}
        ],
        "correctOrder": ["openai-charter", "oecd", "nist", "eu-act"]
      },
      {
        "type": "multiple_choice",
        "id": "q-eu-ai-act",
        "question": "What approach does the EU AI Act take to regulating AI?",
        "options": [
          "Banning all AI development",
          "Risk-based regulation with different rules for different risk levels",
          "Requiring all AI to be open source",
          "Only regulating government AI use"
        ],
        "correctIndex": 1,
        "explanation": "The EU AI Act uses a risk-based approach: minimal-risk AI has few restrictions, while high-risk AI (like hiring tools) must meet strict requirements, and some uses are banned entirely."
      },
      {
        "type": "explain_back",
        "id": "q-explain-governance",
        "concept": "AI governance importance for business",
        "prompt": "Why is AI governance important for businesses deploying AI systems?",
        "rubric": "A good explanation should include: 1) Legal compliance - regulations like EU AI Act have penalties, 2) Risk management - safety failures cause reputational and legal issues, 3) Customer trust - well-governed AI is more reliable, 4) Proactive risk identification before deployment. Credit for mentioning specific regulations or real-world examples of governance failures."
      }
    ]
  },
  {
    "id": "cp-image-gen-1",
    "title": "AI Image Generation Basics",
    "pathId": "ai-image-generation",
    "afterMilestoneId": "E2021_DALLE",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-dalle-innovation",
        "question": "What made DALL-E (2021) significant in AI history?",
        "options": [
          "It was the first image recognition system",
          "It could generate images from text descriptions",
          "It could only process existing photos",
          "It was faster than GANs"
        ],
        "correctIndex": 1,
        "explanation": "DALL-E was revolutionary because it could generate novel images from text prompts, combining language understanding (from transformers) with image generation capabilities."
      },
      {
        "type": "multiple_choice",
        "id": "q-clip-role",
        "question": "What role does CLIP play in image generation systems?",
        "options": [
          "It generates the images directly",
          "It connects text understanding to visual concepts",
          "It compresses image files",
          "It stores images in databases"
        ],
        "correctIndex": 1,
        "explanation": "CLIP learns to match images with text descriptions, enabling systems to understand what 'a sunset over mountains' should look like and guide image generation accordingly."
      }
    ]
  },
  {
    "id": "cp-image-gen-2",
    "title": "Diffusion Models",
    "pathId": "ai-image-generation",
    "afterMilestoneId": "E2022_STABLE_DIFFUSION_RELEASE",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-diffusion-process",
        "question": "How do diffusion models generate images?",
        "options": [
          "By copying parts of existing images",
          "By starting with noise and gradually removing it",
          "By drawing shapes one at a time",
          "By converting text directly to pixels"
        ],
        "correctIndex": 1,
        "explanation": "Diffusion models start with random noise and learn to gradually 'denoise' it into a coherent image, guided by the text prompt. Each step removes some noise until a clear image emerges."
      },
      {
        "type": "matching",
        "id": "q-image-gen-tools",
        "prompt": "Match each tool to its underlying technology:",
        "pairs": [
          {"id": "p1", "left": "Stable Diffusion", "right": "Latent diffusion model"},
          {"id": "p2", "left": "Early StyleGAN", "right": "GAN architecture"},
          {"id": "p3", "left": "DALL-E 2", "right": "Diffusion + CLIP"}
        ]
      },
      {
        "type": "explain_back",
        "id": "q-explain-diffusion-vs-gan",
        "concept": "Diffusion models vs GANs",
        "prompt": "Explain one advantage of diffusion models over GANs for image generation.",
        "rubric": "A good explanation should mention at least one valid advantage: 1) Training stability - diffusion models don't suffer from mode collapse like GANs, 2) Image quality - diffusion often produces higher quality results, 3) Controllability - easier to guide generation with text prompts, 4) Diversity - better at producing varied outputs. Accept any well-explained advantage."
      }
    ]
  },
  {
    "id": "cp-business-1",
    "title": "Early AI in Business",
    "pathId": "ai-for-business",
    "afterMilestoneId": "E1997_DEEP_BLUE",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-expert-systems-use",
        "question": "What was the primary business application of expert systems in the 1980s?",
        "options": [
          "Social media marketing",
          "Encoding specialist knowledge for decision support",
          "Generating creative content",
          "Autonomous vehicle control"
        ],
        "correctIndex": 1,
        "explanation": "Expert systems captured the decision-making knowledge of human specialists, enabling businesses to automate complex decisions in areas like medical diagnosis, loan approval, and equipment maintenance."
      },
      {
        "type": "multiple_choice",
        "id": "q-deep-blue-lesson",
        "question": "What business lesson did Deep Blue's 1997 victory over Kasparov demonstrate?",
        "options": [
          "AI will replace all human workers",
          "Specialized AI can outperform humans in narrow domains",
          "AI is better at everything",
          "Chess players are no longer needed"
        ],
        "correctIndex": 1,
        "explanation": "Deep Blue showed that AI could exceed human capabilities in specific, well-defined tasks. This principle guides AI adoption today: focus AI on narrow domains where it excels, while humans handle broader judgment."
      }
    ]
  },
  {
    "id": "cp-business-2",
    "title": "The Deep Learning Business Impact",
    "pathId": "ai-for-business",
    "afterMilestoneId": "E2020_GPT3",
    "questions": [
      {
        "type": "ordering",
        "id": "q-ai-business-timeline",
        "prompt": "Put these AI business milestones in chronological order:",
        "items": [
          {"id": "expert", "label": "Expert systems in enterprises", "date": "1980s"},
          {"id": "deep-blue", "label": "Deep Blue beats Kasparov", "date": "1997"},
          {"id": "alexnet", "label": "AlexNet enables practical computer vision", "date": "2012"},
          {"id": "gpt3", "label": "GPT-3 enables text generation at scale", "date": "2020"}
        ],
        "correctOrder": ["expert", "deep-blue", "alexnet", "gpt3"]
      },
      {
        "type": "multiple_choice",
        "id": "q-gpt3-business",
        "question": "What new business capability did GPT-3 enable compared to earlier AI?",
        "options": [
          "Image recognition in factories",
          "General-purpose text generation and understanding",
          "Faster database queries",
          "Robotic automation"
        ],
        "correctIndex": 1,
        "explanation": "GPT-3's ability to generate coherent text and follow instructions opened new use cases: customer service automation, content generation, code assistance, and more—tasks that required human language skills."
      },
      {
        "type": "matching",
        "id": "q-ai-business-apps",
        "prompt": "Match each AI milestone to its primary business application:",
        "pairs": [
          {"id": "p1", "left": "Expert Systems", "right": "Decision support & diagnostics"},
          {"id": "p2", "left": "AlexNet/Computer Vision", "right": "Quality inspection & image analysis"},
          {"id": "p3", "left": "GPT-3/LLMs", "right": "Content generation & automation"}
        ]
      }
    ]
  },
  {
    "id": "cp-business-3",
    "title": "Modern AI Strategy",
    "pathId": "ai-for-business",
    "afterMilestoneId": "E2023_GPT4",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-chatgpt-disruption",
        "question": "Why did ChatGPT's launch in 2022 change business AI adoption?",
        "options": [
          "It was the first AI ever created",
          "It made advanced AI accessible through a simple chat interface",
          "It replaced all existing software",
          "It only worked for large corporations"
        ],
        "correctIndex": 1,
        "explanation": "ChatGPT democratized AI by providing a simple, conversational interface. Suddenly anyone could use advanced AI without technical expertise, forcing businesses to quickly develop AI strategies."
      },
      {
        "type": "multiple_choice",
        "id": "q-gpt4-multimodal",
        "question": "What capability did GPT-4 add that expanded business use cases?",
        "options": [
          "Faster text generation only",
          "Multimodal abilities (processing images and text together)",
          "Hardware manufacturing",
          "Physical robot control"
        ],
        "correctIndex": 1,
        "explanation": "GPT-4's multimodal capabilities enabled new applications: analyzing charts and documents, processing receipts, understanding diagrams, and more—expanding AI's usefulness across industries."
      },
      {
        "type": "explain_back",
        "id": "q-explain-ai-strategy",
        "concept": "AI adoption strategy for businesses",
        "prompt": "Based on the evolution from expert systems to GPT-4, what should a business leader consider when adopting AI today?",
        "rubric": "A good response should include: 1) Start with specific, well-defined use cases (lesson from expert systems and Deep Blue), 2) Consider data requirements and availability, 3) Balance automation with human oversight, 4) Stay current as capabilities rapidly evolve (from GPT-3 to GPT-4 in just a few years). Bonus for mentioning risks, costs, or change management."
      }
    ]
  },
  {
    "id": "cp-everyday-1",
    "title": "Quick Check: AI Writing",
    "pathId": "ai-for-everyday-life",
    "afterMilestoneId": "E2020_GPT3",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-everyday-ai-write",
        "question": "What can AI writing tools like GPT-3 do?",
        "options": [
          "Actually understand what they're writing",
          "Predict what words should come next based on patterns",
          "Think and reason like a human",
          "Always give correct information"
        ],
        "correctIndex": 1,
        "explanation": "AI writing tools work by predicting what words should come next, based on patterns from millions of documents. They don't actually understand or think—they're very good at pattern matching."
      },
      {
        "type": "multiple_choice",
        "id": "q-everyday-trust",
        "question": "When should you trust information from AI?",
        "options": [
          "Always—AI is very accurate",
          "Never—AI is always wrong",
          "With caution—verify important information from other sources",
          "Only for medical and legal advice"
        ],
        "correctIndex": 2,
        "explanation": "The best approach is healthy skepticism. AI can be helpful but also confidently wrong. Always verify important information, especially for health, legal, or financial decisions."
      }
    ]
  },
  {
    "id": "cp-everyday-2",
    "title": "Quick Check: AI Images",
    "pathId": "ai-for-everyday-life",
    "afterMilestoneId": "E2021_DALLE",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-everyday-ai-image",
        "question": "How can you often spot an AI-generated image?",
        "options": [
          "AI images are always blurry",
          "Look for strange hands, scrambled text, or odd backgrounds",
          "AI images are always black and white",
          "There's no way to tell"
        ],
        "correctIndex": 1,
        "explanation": "Common signs of AI images include: hands with too many or too few fingers, text that looks scrambled, backgrounds that don't quite make sense, and faces that seem 'too perfect.'"
      },
      {
        "type": "multiple_choice",
        "id": "q-everyday-photo-trust",
        "question": "A friend shares an amazing photo on social media. What should you consider?",
        "options": [
          "All photos online are real",
          "It could be AI-generated, especially if it seems too perfect or outrageous",
          "Only professional photographers use AI",
          "AI can only make cartoon images"
        ],
        "correctIndex": 1,
        "explanation": "AI can now create very realistic photos. If something seems too perfect, too outrageous, or too good to be true, it's worth questioning whether it's real."
      }
    ]
  },
  {
    "id": "cp-everyday-3",
    "title": "Quick Check: ChatGPT",
    "pathId": "ai-for-everyday-life",
    "afterMilestoneId": "E2022_CHATGPT",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-everyday-chatgpt-good",
        "question": "What is ChatGPT good for?",
        "options": [
          "Getting accurate medical diagnosis",
          "Making important financial decisions",
          "Helping draft letters, explain concepts, or brainstorm ideas",
          "Providing legal advice"
        ],
        "correctIndex": 2,
        "explanation": "ChatGPT is helpful for everyday tasks like writing drafts, getting explanations, or brainstorming. But it should never be used for medical, legal, or financial advice—always consult professionals for those."
      },
      {
        "type": "multiple_choice",
        "id": "q-everyday-scam-warning",
        "question": "Your 'grandchild' calls asking for emergency money. The voice sounds like them. What should you do?",
        "options": [
          "Send money immediately—family comes first",
          "Hang up and call them back at their real phone number",
          "Ask for their bank account details",
          "AI can't clone voices, so it must be real"
        ],
        "correctIndex": 1,
        "explanation": "AI can now clone voices very convincingly. If anyone calls asking for money—even if they sound like family—hang up and call them back at a number you know is real. This is a common scam."
      }
    ]
  },
  {
    "id": "cp-everyday-4",
    "title": "Final Check: AI Today",
    "pathId": "ai-for-everyday-life",
    "afterMilestoneId": "E2023_GPT4",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-everyday-ai-limits",
        "question": "What should you remember about AI tools like ChatGPT and GPT-4?",
        "options": [
          "They're always correct because they're computers",
          "They can be confidently wrong, so always verify important information",
          "They have no practical uses",
          "They're too complicated for regular people to use"
        ],
        "correctIndex": 1,
        "explanation": "AI tools can be very helpful, but they can also be confidently wrong. Always verify important information from trusted sources, especially for health, money, or legal matters."
      },
      {
        "type": "multiple_choice",
        "id": "q-everyday-safe-use",
        "question": "What's a safe way to try AI tools like ChatGPT?",
        "options": [
          "Share your social security number to verify your identity",
          "Give it your passwords so it can help with your accounts",
          "Ask it to explain something you're curious about, like a recipe or hobby",
          "Tell it your bank account information"
        ],
        "correctIndex": 2,
        "explanation": "Never share personal information like passwords, social security numbers, or financial details with AI tools. Safe uses include asking questions, getting explanations, or help with writing—nothing that requires sensitive information."
      }
    ]
  },
  {
    "id": "cp-pop-culture-1",
    "title": "The Shock Heard Round the World",
    "pathId": "pop-culture",
    "afterMilestoneId": "E2016_ALPHAGO",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-alphago-significance",
        "question": "Why was AlphaGo's victory over Lee Sedol considered more significant than Deep Blue beating Kasparov at chess?",
        "options": [
          "Go has more possible positions than atoms in the universe, requiring intuition not just calculation",
          "Lee Sedol was a better player than Kasparov",
          "Chess was already solved by computers",
          "AlphaGo used quantum computing"
        ],
        "correctIndex": 0,
        "explanation": "Go's complexity (10^170 possible positions) meant brute-force calculation was impossible. AlphaGo had to develop something resembling intuition, which is why Lee Sedol's creative 'God Move' in Game 4—which briefly confused the AI—became so legendary."
      },
      {
        "type": "multiple_choice",
        "id": "q-alphago-cultural",
        "question": "What made AlphaGo's victory a cultural moment beyond just a technical achievement?",
        "options": [
          "It was the first time AI appeared on television",
          "Go is deeply significant in Asian culture and millions watched the match live",
          "Lee Sedol became a celebrity afterward",
          "Google paid viewers to watch"
        ],
        "correctIndex": 1,
        "explanation": "Go holds deep cultural significance in East Asia, particularly in South Korea. The match was watched by over 200 million people worldwide, making it one of the most-watched AI demonstrations in history."
      }
    ]
  },
  {
    "id": "cp-pop-culture-2",
    "title": "AI Gets Creative (and Controversial)",
    "pathId": "pop-culture",
    "afterMilestoneId": "E2023_AI_DRAKE_SONG",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-drake-controversy",
        "question": "What made the AI Drake/Weeknd song 'Heart on My Sleeve' so controversial?",
        "options": [
          "It was poorly made",
          "It demonstrated AI could convincingly mimic specific artists' voices without permission",
          "Drake and The Weeknd collaborated on it secretly",
          "It won a Grammy award"
        ],
        "correctIndex": 1,
        "explanation": "The song showed that AI could create convincing imitations of specific artists, raising urgent questions about voice rights, authenticity, and whether AI-generated music should be allowed on streaming platforms."
      },
      {
        "type": "multiple_choice",
        "id": "q-ai-creative-rights",
        "question": "What broader question did the AI Drake song raise for the music industry?",
        "options": [
          "Whether streaming services should pay higher royalties",
          "Whether AI should be allowed to perform live concerts",
          "Whether artists have rights over AI imitations of their voices and styles",
          "Whether all music should be free"
        ],
        "correctIndex": 2,
        "explanation": "The incident highlighted a major legal gray area: current copyright law protects songs, but there's no clear protection for an artist's voice or style. This has sparked ongoing debates about AI and creative rights."
      }
    ]
  },
  {
    "id": "cp-pop-culture-3",
    "title": "ChatGPT Changes Everything",
    "pathId": "pop-culture",
    "afterMilestoneId": "E2023_HOLLYWOOD_AI_STRIKES",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-hollywood-strike-first",
        "question": "What historic first did the 2023 Hollywood strikes represent?",
        "options": [
          "Longest strike in entertainment history",
          "First major labor action with AI protections as a central demand",
          "First time writers and actors struck simultaneously",
          "First strike to be resolved by AI mediation"
        ],
        "correctIndex": 1,
        "explanation": "The WGA and SAG-AFTRA strikes were the first major labor actions where protections against AI replacement were key demands. The resulting contracts set precedents for how AI can and cannot be used in creative industries."
      },
      {
        "type": "multiple_choice",
        "id": "q-hollywood-concerns",
        "question": "What were writers and actors specifically concerned about regarding AI?",
        "options": [
          "AI taking credit for their work",
          "Being replaced by AI-generated scripts and digital likenesses without consent",
          "AI making movies too expensive",
          "AI critics giving bad reviews"
        ],
        "correctIndex": 1,
        "explanation": "Writers feared AI would be used to generate scripts without human writers, while actors worried about studios using their digital likenesses without consent or fair compensation."
      }
    ]
  },
  {
    "id": "cp-pop-culture-4",
    "title": "The Ethics Wars",
    "pathId": "pop-culture",
    "afterMilestoneId": "E2023_PAUSE_AI_LETTER",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-pause-letter-meaning",
        "question": "What does the 'Pause Giant AI' letter represent in the AI safety debate?",
        "options": [
          "Universal scientific consensus that AI should be paused",
          "A prominent example of the tension between AI accelerationists and safety advocates",
          "A legally binding agreement signed by AI companies",
          "A letter only signed by people outside the AI industry"
        ],
        "correctIndex": 1,
        "explanation": "The letter crystallized the growing divide between those who want to rapidly advance AI capabilities and those calling for caution. While signed by notable figures like Elon Musk, many AI researchers disagreed, showing the field's lack of consensus on safety."
      },
      {
        "type": "multiple_choice",
        "id": "q-gebru-significance",
        "question": "Why was Timnit Gebru's departure from Google considered significant?",
        "options": [
          "She was the CEO of Google",
          "It highlighted tensions between AI ethics research and corporate interests",
          "She invented the transformer architecture",
          "She was the first woman in AI"
        ],
        "correctIndex": 1,
        "explanation": "Gebru's departure sparked industry-wide debate about whether corporations can conduct meaningful AI ethics research while also commercializing AI, and raised questions about diversity and power in tech."
      }
    ]
  },
  {
    "id": "cp-pop-culture-5",
    "title": "Silicon Valley Drama",
    "pathId": "pop-culture",
    "afterMilestoneId": "E2023_OPENAI_BOARD_CRISIS",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-openai-crisis-tension",
        "question": "What fundamental tension did the OpenAI board crisis expose?",
        "options": [
          "Disagreements about which programming language to use",
          "The conflict between nonprofit AI safety governance and commercial pressures",
          "Personal rivalry between Sam Altman and Elon Musk",
          "Technical disagreements about transformer architecture"
        ],
        "correctIndex": 1,
        "explanation": "OpenAI was founded as a nonprofit focused on AI safety, but became a capped-profit company with massive commercial interests. The board crisis revealed how difficult it is to balance safety-focused governance with the pressures of being the hottest AI company in the world."
      },
      {
        "type": "multiple_choice",
        "id": "q-openai-crisis-outcome",
        "question": "What did the outcome of the OpenAI crisis suggest about AI company governance?",
        "options": [
          "Nonprofit boards are the best way to govern AI companies",
          "Employees have no power in tech companies",
          "Commercial interests and talent retention often outweigh governance concerns",
          "Sam Altman was universally beloved"
        ],
        "correctIndex": 2,
        "explanation": "When 95% of employees threatened to quit and Microsoft offered Altman a job, the board capitulated within days. This showed that in practice, commercial interests and talent retention can overwhelm even well-intentioned governance structures."
      },
      {
        "type": "explain_back",
        "id": "q-explain-pop-culture-impact",
        "concept": "AI's cultural impact",
        "prompt": "Based on what you've learned, why do you think viral moments and celebrity controversies have shaped public perception of AI more than technical papers?",
        "rubric": "A good response should include: 1) Technical papers are inaccessible to most people, 2) Drama and controversy create emotional engagement and are widely shared, 3) Celebrity involvement brings mainstream media attention, 4) These moments create concrete examples people can relate to. Credit for mentioning specific examples from the path."
      }
    ]
  },
  {
    "id": "cp-leaders-1",
    "title": "Strategic AI Understanding",
    "pathId": "ai-for-leaders",
    "afterMilestoneId": "E2020_GPT3",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-leaders-first-movers",
        "question": "What competitive advantage do early AI adopters typically have?",
        "options": [
          "They can charge premium prices for any AI-related product",
          "They've built workflows, data advantages, and institutional knowledge",
          "They can prevent competitors from using AI",
          "They automatically become market leaders"
        ],
        "correctIndex": 1,
        "explanation": "Early adopters don't just have technology—they've built processes, collected feedback data, and developed organizational expertise. Late adopters must build all this from scratch while competitors continue advancing."
      },
      {
        "type": "multiple_choice",
        "id": "q-leaders-ai-economics",
        "question": "What changed about AI economics when GPT-3 introduced API access?",
        "options": [
          "AI became free for everyone to use",
          "Only large tech companies could afford AI",
          "Organizations could access AI capabilities without building ML teams",
          "AI costs increased dramatically"
        ],
        "correctIndex": 2,
        "explanation": "API access democratized AI—you could pay per use rather than hiring expensive ML teams. This shifted AI from 'big tech only' to 'accessible for many organizations,' dramatically expanding who could benefit."
      }
    ]
  },
  {
    "id": "cp-leaders-2",
    "title": "AI Adoption Strategy",
    "pathId": "ai-for-leaders",
    "afterMilestoneId": "E2022_CHATGPT",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-leaders-shadow-ai",
        "question": "You discover 40% of employees are using ChatGPT for work without a company policy. What's the best first response?",
        "options": [
          "Ban all AI usage immediately",
          "Do nothing and let employees figure it out",
          "Create guidelines for safe use while protecting sensitive data",
          "Wait to see what competitors do"
        ],
        "correctIndex": 2,
        "explanation": "Banning AI often drives it underground (employees use it anyway, just secretly). The best approach acknowledges reality: create clear guidelines that enable productive use while protecting sensitive information."
      },
      {
        "type": "multiple_choice",
        "id": "q-leaders-adoption-speed",
        "question": "ChatGPT reached 100 million users in two months. What does this adoption speed signal for organizations?",
        "options": [
          "It's just a consumer fad that won't affect business",
          "You have years to develop an AI strategy",
          "Competitive pressure is intense and waiting is risky",
          "Only tech companies need to pay attention"
        ],
        "correctIndex": 2,
        "explanation": "The fastest product adoption in history signals that customer and employee expectations are shifting rapidly. Organizations without AI strategies risk falling behind competitors who are already integrating these capabilities."
      }
    ]
  },
  {
    "id": "cp-leaders-3",
    "title": "AI Governance and Risk",
    "pathId": "ai-for-leaders",
    "afterMilestoneId": "E2024_EU_AI_ACT",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-leaders-eu-compliance",
        "question": "Your company serves EU customers and uses AI for hiring decisions. Under the EU AI Act, what's required?",
        "options": [
          "Nothing—the law only applies to EU-based companies",
          "Documentation, human oversight, and conformity assessments",
          "Just a privacy notice on your website",
          "Approval from EU regulators before any AI use"
        ],
        "correctIndex": 1,
        "explanation": "The EU AI Act applies to any company serving EU customers, regardless of where the company is based. AI used for hiring is classified as 'high-risk' and requires documentation, human oversight, and conformity assessments."
      },
      {
        "type": "multiple_choice",
        "id": "q-leaders-ai-risk",
        "question": "Which approach best describes responsible enterprise AI adoption?",
        "options": [
          "Move fast, apologize later if things go wrong",
          "Wait until AI is completely safe before any adoption",
          "Start with lower-risk use cases while building governance",
          "Only use AI if competitors are already using it"
        ],
        "correctIndex": 2,
        "explanation": "The best approach balances opportunity and risk: start with use cases where errors are less consequential, build internal expertise, and develop governance frameworks before expanding to higher-stakes applications."
      }
    ]
  },
  {
    "id": "cp-applied-ai-1",
    "title": "The API Revolution",
    "pathId": "applied-ai",
    "afterMilestoneId": "E2020_GPT3_API",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-api-first-advantage",
        "question": "What business advantage did the GPT-3 API provide over previous AI approaches?",
        "options": [
          "It was completely free to use",
          "It allowed companies to build AI products without ML teams",
          "It guaranteed 100% accuracy on all tasks",
          "It replaced the need for any human workers"
        ],
        "correctIndex": 1,
        "explanation": "The GPT-3 API democratized AI by letting any developer build AI-powered products by making API calls. Previously, using cutting-edge AI required expensive ML teams and infrastructure."
      },
      {
        "type": "multiple_choice",
        "id": "q-api-cost-model",
        "question": "How does API-first AI pricing typically work?",
        "options": [
          "One-time purchase of the model",
          "Pay per use based on tokens processed",
          "Free with advertising",
          "Fixed monthly fee regardless of usage"
        ],
        "correctIndex": 1,
        "explanation": "API-first AI uses pay-per-use pricing, typically based on tokens (pieces of text) processed. This enables low-cost experimentation but can scale to significant costs at high volume."
      }
    ]
  },
  {
    "id": "cp-applied-ai-2",
    "title": "AI in the Developer Workflow",
    "pathId": "applied-ai",
    "afterMilestoneId": "E2021_COPILOT",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-copilot-limitation",
        "question": "What's a key limitation of AI coding assistants like GitHub Copilot?",
        "options": [
          "They only work with Python",
          "They can suggest buggy or insecure code that requires review",
          "They're too slow to be practical",
          "They can only write comments, not code"
        ],
        "correctIndex": 1,
        "explanation": "AI coding assistants frequently suggest code with bugs, security vulnerabilities, or patterns from training data that may not fit your context. Human review remains essential."
      },
      {
        "type": "matching",
        "id": "q-ai-copilot-match",
        "prompt": "Match each AI copilot to its primary use case:",
        "pairs": [
          {"id": "p1", "left": "GitHub Copilot", "right": "Code completion in IDEs"},
          {"id": "p2", "left": "Microsoft 365 Copilot", "right": "Office document assistance"},
          {"id": "p3", "left": "AWS CodeWhisperer", "right": "AWS-integrated code suggestions"}
        ]
      }
    ]
  },
  {
    "id": "cp-applied-ai-3",
    "title": "Enterprise AI Integration",
    "pathId": "applied-ai",
    "afterMilestoneId": "E2023_ENTERPRISE_AI",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-enterprise-vs-consumer",
        "question": "What distinguishes enterprise AI from consumer AI tools like ChatGPT?",
        "options": [
          "Enterprise AI is always more accurate",
          "Enterprise AI includes data isolation, compliance, and integration features",
          "Enterprise AI is free for businesses",
          "Enterprise AI doesn't use the same underlying technology"
        ],
        "correctIndex": 1,
        "explanation": "Enterprise AI isn't just about capability—it's about deploying AI safely with data isolation, access controls, audit logging, compliance certifications, and integration with existing business systems."
      },
      {
        "type": "multiple_choice",
        "id": "q-shadow-ai-risk",
        "question": "You discover employees are using personal ChatGPT accounts for work. What's the primary risk?",
        "options": [
          "The AI might give wrong answers",
          "Sensitive company data could be exposed without proper controls",
          "It's illegal to use AI at work",
          "ChatGPT is slower than enterprise alternatives"
        ],
        "correctIndex": 1,
        "explanation": "'Shadow AI' (unauthorized AI use) risks exposing sensitive data to systems without proper security controls. Consumer AI tools may train on user inputs and lack enterprise data protection."
      }
    ]
  },
  {
    "id": "cp-applied-ai-4",
    "title": "AI Agents in Practice",
    "pathId": "applied-ai",
    "afterMilestoneId": "E2024_AI_AGENTS",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-agent-vs-chatbot",
        "question": "What distinguishes an AI agent from a chatbot?",
        "options": [
          "Agents are always more accurate",
          "Agents can take actions and use tools, not just generate text",
          "Agents don't use language models",
          "Agents require no human oversight"
        ],
        "correctIndex": 1,
        "explanation": "AI agents go beyond conversation—they can search the web, call APIs, write files, and take other actions to complete tasks. This moves AI from assistant to worker, though with increased complexity and risk."
      },
      {
        "type": "multiple_choice",
        "id": "q-agent-failure",
        "question": "What's a common failure mode when deploying AI agents?",
        "options": [
          "They run too fast",
          "They get stuck in loops or take unintended actions",
          "They cost less than expected",
          "They're too transparent about what they're doing"
        ],
        "correctIndex": 1,
        "explanation": "Agents can fail in complex ways: getting stuck repeating ineffective actions, taking actions outside their intended scope, or cascading errors through multi-step processes. Human oversight and clear boundaries are essential."
      }
    ]
  },
  {
    "id": "cp-applied-ai-5",
    "title": "RAG and Enterprise Knowledge",
    "pathId": "applied-ai",
    "afterMilestoneId": "E2024_RAG_ADOPTION",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-rag-purpose",
        "question": "What problem does RAG (Retrieval-Augmented Generation) solve?",
        "options": [
          "Making AI models smaller",
          "Connecting AI to current, proprietary data it wasn't trained on",
          "Eliminating the need for vector databases",
          "Replacing human oversight entirely"
        ],
        "correctIndex": 1,
        "explanation": "RAG solves the knowledge gap: LLMs know what was in their training data but not your company's latest documents. RAG retrieves relevant information from your knowledge base before generating responses."
      },
      {
        "type": "multiple_choice",
        "id": "q-rag-misconception",
        "question": "Which statement about RAG is FALSE?",
        "options": [
          "RAG can reduce hallucinations by grounding responses in real documents",
          "RAG requires a vector database to store document embeddings",
          "RAG completely eliminates the possibility of AI hallucinations",
          "RAG is commonly used for enterprise Q&A and knowledge assistants"
        ],
        "correctIndex": 2,
        "explanation": "RAG reduces hallucinations but doesn't eliminate them. The LLM can still misinterpret, ignore, or incorrectly synthesize retrieved information. Human review remains important for critical applications."
      },
      {
        "type": "explain_back",
        "id": "q-explain-build-vs-buy",
        "concept": "Build vs. buy for enterprise AI",
        "prompt": "Based on what you've learned about applied AI, when should a company build custom AI solutions versus buying enterprise AI products?",
        "rubric": "A good response should consider: 1) Buy when standard use cases apply (office productivity, basic chatbots), 2) Build when differentiation matters or proprietary data/workflows are central, 3) Consider hybrid approaches (APIs + custom integration), 4) Factor in maintenance burden and team expertise. Credit for mentioning specific examples like RAG for knowledge bases or copilots for standard workflows."
      }
    ]
  },
  {
    "id": "cp-coding-ai-1",
    "title": "Understanding AI Coding Tools",
    "pathId": "coding-with-ai",
    "afterMilestoneId": "E2021_COPILOT",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-copilot-role",
        "question": "What was GitHub Copilot's main innovation when it launched?",
        "options": [
          "It could write entire applications from scratch",
          "It suggested contextual code completions based on what you're working on",
          "It replaced the need for human programmers",
          "It only worked with Python code"
        ],
        "correctIndex": 1,
        "explanation": "Copilot's key innovation was understanding your code context—comments, function names, surrounding code—to suggest relevant completions. It doesn't write whole apps or replace programmers, but it dramatically speeds up routine coding tasks."
      },
      {
        "type": "multiple_choice",
        "id": "q-copilot-limitation",
        "question": "What's a key limitation you should know about AI coding assistants?",
        "options": [
          "They only work in English-speaking countries",
          "They can suggest buggy or insecure code that requires human review",
          "They're too slow for practical use",
          "They can only work offline"
        ],
        "correctIndex": 1,
        "explanation": "AI coding assistants frequently suggest code with bugs, security vulnerabilities, or patterns that don't fit your specific context. Human review is essential—never blindly accept AI suggestions without understanding and testing them."
      }
    ]
  },
  {
    "id": "cp-coding-ai-2",
    "title": "Which Prompt Works Better?",
    "pathId": "coding-with-ai",
    "afterMilestoneId": "E2025_VIBE_CODING",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-prompt-compare-1",
        "question": "You want AI to create a to-do list app. Which prompt will get better results?",
        "options": [
          "Make me a to-do app",
          "Create a simple to-do list using HTML, CSS, and JavaScript with add, complete, and delete features, storing tasks in localStorage, in a single HTML file",
          "I need an app for tasks",
          "Build something for productivity"
        ],
        "correctIndex": 1,
        "explanation": "The second prompt specifies the technology (HTML/CSS/JS), features (add, complete, delete), persistence method (localStorage), and constraints (single file). Vague prompts like 'make me an app' leave too much undefined and often produce unusable results."
      },
      {
        "type": "multiple_choice",
        "id": "q-debugging-approach",
        "question": "Your AI-generated code doesn't work. Which approach is best?",
        "options": [
          "Say 'This doesn't work, please fix it' and paste the code",
          "Start over with a completely different prompt",
          "Give up—AI coding doesn't work",
          "Paste the exact error message and describe what happened vs. what you expected"
        ],
        "correctIndex": 3,
        "explanation": "Including the specific error message tells AI exactly where to look. Saying 'doesn't work' could mean many things. The more specific you are about what went wrong, the better AI can help you fix it."
      },
      {
        "type": "multiple_choice",
        "id": "q-vibe-coding-myth",
        "question": "Which statement about 'vibe coding' is FALSE?",
        "options": [
          "You can build working software by describing what you want in English",
          "You don't need any skills—AI handles everything perfectly",
          "Testing and iteration are still essential",
          "It's changing who can participate in software creation"
        ],
        "correctIndex": 1,
        "explanation": "Vibe coding requires real skills: clear thinking about requirements, understanding enough to verify results, and iterating when things don't work. AI isn't magic—it's a powerful tool that still needs human judgment and verification."
      }
    ]
  },
  {
    "id": "cp-coding-ai-3",
    "title": "Context Engineering Essentials",
    "pathId": "coding-with-ai",
    "afterMilestoneId": "E2025_CONTEXT_ENGINEERING",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-context-purpose",
        "question": "What is the main purpose of a CLAUDE.md or .cursorrules file?",
        "options": [
          "To store your API keys securely",
          "To give AI context about your project before you ask questions",
          "To compile your code faster",
          "To hide files from version control"
        ],
        "correctIndex": 1,
        "explanation": "Context files give AI information about your project—what it does, what technologies you use, your preferences and constraints. This helps AI understand your project before you ask anything, leading to better, more relevant responses."
      },
      {
        "type": "multiple_choice",
        "id": "q-context-content",
        "question": "What should a good context file include?",
        "options": [
          "Your complete git history and every file in the project",
          "Project description, tech stack, commands to run/test, and coding preferences",
          "Only the name of your project",
          "Detailed documentation of every function"
        ],
        "correctIndex": 1,
        "explanation": "Good context files are concise and scannable: what the project does, your tech stack, how to run and test it, and key preferences or constraints. AI can read your actual code for details—the context file tells it how to think about your project."
      },
      {
        "type": "multiple_choice",
        "id": "q-context-mistake",
        "question": "What's a common context engineering mistake?",
        "options": [
          "Including commands to run and test the project",
          "Writing too much—making the context file exhaustive instead of scannable",
          "Mentioning your preferred coding patterns",
          "Describing what the project does"
        ],
        "correctIndex": 1,
        "explanation": "More context isn't always better. Long, detailed context files can actually hurt results because AI may miss important information in the noise. Keep context files focused on what actually helps AI understand your project."
      }
    ]
  },
  {
    "id": "cp-coding-ai-4",
    "title": "Tool Selection & Human Judgment",
    "pathId": "coding-with-ai",
    "afterMilestoneId": "E2024_CLAUDE_CODE",
    "questions": [
      {
        "type": "multiple_choice",
        "id": "q-tool-autonomy",
        "question": "What distinguishes 'agentic' AI coding tools like Claude Code from autocomplete tools like Copilot?",
        "options": [
          "Agentic tools are always more accurate",
          "Agentic tools can take actions like running commands and editing multiple files",
          "Autocomplete tools require no human oversight",
          "Agentic tools only work in the browser"
        ],
        "correctIndex": 1,
        "explanation": "Agentic tools go beyond suggestions—they can read files, make edits, run commands, and complete multi-step tasks. This makes them more powerful but also requires more careful oversight since they're taking real actions on your system."
      },
      {
        "type": "multiple_choice",
        "id": "q-human-judgment",
        "question": "When using AI coding tools, which tasks still require human judgment?",
        "options": [
          "Writing simple boilerplate code",
          "Security decisions, testing, and verifying the code does what you wanted",
          "Formatting code consistently",
          "Looking up documentation"
        ],
        "correctIndex": 1,
        "explanation": "AI can write code, but humans must verify it actually does what was intended, check for security issues, test edge cases, and make judgment calls about design. Never deploy AI-generated code without testing and review."
      },
      {
        "type": "explain_back",
        "id": "q-explain-first-project",
        "concept": "Getting started with AI-assisted coding",
        "prompt": "What would you build as your first 'vibe coding' project, and what steps would you take to create it?",
        "rubric": "A good response should: 1) Choose something simple and achievable (single HTML file, basic tool), 2) Describe what the project does specifically (not vaguely), 3) Mention which AI tool they'd use, 4) Include testing/iteration as part of the process. Credit for realistic expectations about complexity and the need to refine results."
      }
    ]
  }
]
